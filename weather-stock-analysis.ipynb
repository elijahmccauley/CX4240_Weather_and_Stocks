{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97fdf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "import glob\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define paths based on your repository structure\n",
    "weather_data_dir = \"weather_data\"\n",
    "stock_data_dir = \"clean_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7503cc1",
   "metadata": {},
   "source": [
    "## 1. Loading and Initial Data Preparation\n",
    "\n",
    "load both stock and weather data, then start preparing them for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a141198c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock data from individual ticker files...\n",
      "Found 172 stock files\n",
      "Combined stock data shape: (617824, 30)\n",
      "Date range: 2010-01-04 00:00:00 to 2024-12-20 00:00:00\n",
      "Number of unique stocks: 172\n",
      "Example stock features: ['Date', 'Symbol', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume', 'ema15', 'ema50']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ema15</th>\n",
       "      <th>ema50</th>\n",
       "      <th>...</th>\n",
       "      <th>vwap</th>\n",
       "      <th>roc_10</th>\n",
       "      <th>Target</th>\n",
       "      <th>Clopen</th>\n",
       "      <th>HighLow</th>\n",
       "      <th>log_price</th>\n",
       "      <th>Log5</th>\n",
       "      <th>Log15</th>\n",
       "      <th>Log30</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>21.629181</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>34.099998</td>\n",
       "      <td>34.919998</td>\n",
       "      <td>13767900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.005727</td>\n",
       "      <td>1.038123</td>\n",
       "      <td>3.558771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>21.450581</td>\n",
       "      <td>34.830002</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>34.160000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>16739300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995143</td>\n",
       "      <td>1.024590</td>\n",
       "      <td>3.550479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>21.179594</td>\n",
       "      <td>34.389999</td>\n",
       "      <td>34.889999</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>34.619999</td>\n",
       "      <td>21372100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993356</td>\n",
       "      <td>1.018686</td>\n",
       "      <td>3.537766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>21.222700</td>\n",
       "      <td>34.459999</td>\n",
       "      <td>35.450001</td>\n",
       "      <td>34.150002</td>\n",
       "      <td>34.150002</td>\n",
       "      <td>17897100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009078</td>\n",
       "      <td>1.038067</td>\n",
       "      <td>3.539799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>20.760809</td>\n",
       "      <td>33.709999</td>\n",
       "      <td>34.639999</td>\n",
       "      <td>33.360001</td>\n",
       "      <td>34.290001</td>\n",
       "      <td>17863300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983085</td>\n",
       "      <td>1.038369</td>\n",
       "      <td>3.517795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Symbol  Adj Close      Close       High        Low       Open  \\\n",
       "0 2013-01-02   ABBV  21.629181  35.119999  35.400002  34.099998  34.919998   \n",
       "1 2013-01-03   ABBV  21.450581  34.830002  35.000000  34.160000  35.000000   \n",
       "2 2013-01-04   ABBV  21.179594  34.389999  34.889999  34.250000  34.619999   \n",
       "3 2013-01-07   ABBV  21.222700  34.459999  35.450001  34.150002  34.150002   \n",
       "4 2013-01-08   ABBV  20.760809  33.709999  34.639999  33.360001  34.290001   \n",
       "\n",
       "       Volume  ema15  ema50  ...  vwap  roc_10  Target    Clopen   HighLow  \\\n",
       "0  13767900.0    NaN    NaN  ...   NaN     NaN       0  1.005727  1.038123   \n",
       "1  16739300.0    NaN    NaN  ...   NaN     NaN       0  0.995143  1.024590   \n",
       "2  21372100.0    NaN    NaN  ...   NaN     NaN       1  0.993356  1.018686   \n",
       "3  17897100.0    NaN    NaN  ...   NaN     NaN       0  1.009078  1.038067   \n",
       "4  17863300.0    NaN    NaN  ...   NaN     NaN       1  0.983085  1.038369   \n",
       "\n",
       "   log_price  Log5  Log15  Log30  Ticker  \n",
       "0   3.558771   NaN    NaN    NaN    ABBV  \n",
       "1   3.550479   NaN    NaN    NaN    ABBV  \n",
       "2   3.537766   NaN    NaN    NaN    ABBV  \n",
       "3   3.539799   NaN    NaN    NaN    ABBV  \n",
       "4   3.517795   NaN    NaN    NaN    ABBV  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Load and prepare stock data from individual ticker files\n",
    "print(\"Loading stock data from individual ticker files...\")\n",
    "# Get all CSV files in the clean_data directory\n",
    "stock_files = glob.glob(os.path.join(stock_data_dir, \"*.csv\"))\n",
    "print(f\"Found {len(stock_files)} stock files\")\n",
    "\n",
    "# Load each file and add the ticker information\n",
    "dataframes = []\n",
    "for file in stock_files:\n",
    "    ticker = os.path.basename(file).split('.')[0]  # Extract ticker from filename\n",
    "    df = pd.read_csv(file)\n",
    "    if 'Ticker' not in df.columns:  # Only add if not already present\n",
    "        df['Ticker'] = ticker\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all stock data\n",
    "stock_data = pd.concat(dataframes, ignore_index=True)\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Combined stock data shape: {stock_data.shape}\")\n",
    "print(f\"Date range: {stock_data['Date'].min()} to {stock_data['Date'].max()}\")\n",
    "print(f\"Number of unique stocks: {stock_data['Ticker'].nunique()}\")\n",
    "print(\"Example stock features:\", list(stock_data.columns[:10]))\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d628cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weather data...\n",
      "Processing New York weather data...\n",
      "NY weather data shape: (9133, 12)\n",
      "Weather date range: 2000-02-02 04:00:00+00:00 to 2025-02-02 04:00:00+00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_gusts_10m_max</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>snowfall_sum</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>daylight_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-02-02 04:00:00+00:00</td>\n",
       "      <td>-6.195917</td>\n",
       "      <td>-3.548</td>\n",
       "      <td>-8.747999</td>\n",
       "      <td>27.971327</td>\n",
       "      <td>52.199997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33045.746</td>\n",
       "      <td>36505.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-03 04:00:00+00:00</td>\n",
       "      <td>-6.373001</td>\n",
       "      <td>-1.748</td>\n",
       "      <td>-11.297999</td>\n",
       "      <td>13.104197</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7588.906</td>\n",
       "      <td>36639.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-02-04 04:00:00+00:00</td>\n",
       "      <td>-3.191750</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-6.648000</td>\n",
       "      <td>9.178235</td>\n",
       "      <td>20.519999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29841.834</td>\n",
       "      <td>36774.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-02-05 04:00:00+00:00</td>\n",
       "      <td>-3.554250</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>-6.098000</td>\n",
       "      <td>18.193361</td>\n",
       "      <td>32.760002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33403.030</td>\n",
       "      <td>36910.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-02-06 04:00:00+00:00</td>\n",
       "      <td>-4.579250</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-7.698000</td>\n",
       "      <td>18.720000</td>\n",
       "      <td>35.280000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33629.734</td>\n",
       "      <td>37047.720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  temperature_2m_mean  temperature_2m_max  \\\n",
       "0 2000-02-02 04:00:00+00:00            -6.195917              -3.548   \n",
       "1 2000-02-03 04:00:00+00:00            -6.373001              -1.748   \n",
       "2 2000-02-04 04:00:00+00:00            -3.191750               0.002   \n",
       "3 2000-02-05 04:00:00+00:00            -3.554250              -0.648   \n",
       "4 2000-02-06 04:00:00+00:00            -4.579250              -0.248   \n",
       "\n",
       "   temperature_2m_min  wind_speed_10m_max  wind_gusts_10m_max  rain_sum  \\\n",
       "0           -8.747999           27.971327           52.199997       0.0   \n",
       "1          -11.297999           13.104197           28.800000       0.0   \n",
       "2           -6.648000            9.178235           20.519999       0.0   \n",
       "3           -6.098000           18.193361           32.760002       0.0   \n",
       "4           -7.698000           18.720000           35.280000       0.0   \n",
       "\n",
       "   snowfall_sum  precipitation_sum  precipitation_hours  sunshine_duration  \\\n",
       "0          0.00                0.0                  0.0          33045.746   \n",
       "1          0.63                0.9                  5.0           7588.906   \n",
       "2          0.56                0.6                  2.0          29841.834   \n",
       "3          0.14                0.0                  0.0          33403.030   \n",
       "4          0.00                0.0                  0.0          33629.734   \n",
       "\n",
       "   daylight_duration  \n",
       "0          36505.156  \n",
       "1          36639.310  \n",
       "2          36774.555  \n",
       "3          36910.740  \n",
       "4          37047.720  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Load weather data\n",
    "print(\"Loading weather data...\")\n",
    "daily_weather_path = os.path.join(weather_data_dir, \"combined_daily_weather_data.csv\")\n",
    "weather_df = pd.read_csv(daily_weather_path)\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "\n",
    "# For S&P 500 stocks, we'll primarily use New York weather\n",
    "# Filter to keep only New York weather\n",
    "print(\"Processing New York weather data...\")\n",
    "ny_weather = weather_df[weather_df['location'] == 'New_York'].copy()\n",
    "ny_weather = ny_weather.rename(columns={'date': 'Date'})\n",
    "\n",
    "# Select relevant weather features\n",
    "weather_features = [\n",
    "    'temperature_2m_mean', 'temperature_2m_max', 'temperature_2m_min',\n",
    "    'wind_speed_10m_max', 'wind_gusts_10m_max', 'rain_sum',\n",
    "    'snowfall_sum', 'precipitation_sum', 'precipitation_hours',\n",
    "    'sunshine_duration', 'daylight_duration'\n",
    "]\n",
    "ny_weather = ny_weather[['Date'] + weather_features]\n",
    "\n",
    "# Display basic information\n",
    "print(f\"NY weather data shape: {ny_weather.shape}\")\n",
    "print(f\"Weather date range: {ny_weather['Date'].min()} to {ny_weather['Date'].max()}\")\n",
    "ny_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f2364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling seasonality in weather data...\n",
      "Examples of extreme temperature anomalies:\n",
      "                          Date  temperature_2m_mean  \\\n",
      "6233 2017-02-25 04:00:00+00:00            11.286835   \n",
      "7535 2020-09-19 04:00:00+00:00            12.566001   \n",
      "335  2001-01-02 04:00:00+00:00           -10.312583   \n",
      "5497 2015-02-20 04:00:00+00:00           -15.454250   \n",
      "7251 2019-12-10 04:00:00+00:00            10.805584   \n",
      "\n",
      "      temperature_2m_mean_seasonal_avg  temperature_2m_mean_seasonal_zscore  \\\n",
      "6233                          1.113397                             2.146721   \n",
      "7535                         18.431981                            -2.170017   \n",
      "335                           0.373457                            -2.401723   \n",
      "5497                          0.068397                            -2.887905   \n",
      "7251                          2.258647                             2.024786   \n",
      "\n",
      "     season_name  \n",
      "6233      Winter  \n",
      "7535      Summer  \n",
      "335       Winter  \n",
      "5497      Winter  \n",
      "7251        Fall  \n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Handle Seasonality in Weather Data\n",
    "print(\"Handling seasonality in weather data...\")\n",
    "\n",
    "# Add explicit seasonal features\n",
    "ny_weather['month'] = ny_weather['Date'].dt.month\n",
    "ny_weather['day_of_year'] = ny_weather['Date'].dt.dayofyear\n",
    "ny_weather['season'] = np.ceil(ny_weather['month']/3).astype(int)\n",
    "ny_weather['season'] = ny_weather['season'].replace({5:1})  # Fix any values over 4\n",
    "\n",
    "# Map seasons to names for easier interpretation\n",
    "season_map = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "ny_weather['season_name'] = ny_weather['season'].map(season_map)\n",
    "\n",
    "# Create seasonal averages for temperature and precipitation\n",
    "for feature in ['temperature_2m_mean', 'precipitation_sum']:\n",
    "    # Calculate multi-year seasonal average for each day of year\n",
    "    seasonal_avg = ny_weather.groupby('day_of_year')[feature].transform('mean')\n",
    "    ny_weather[f'{feature}_seasonal_avg'] = seasonal_avg\n",
    "    \n",
    "    # Calculate deviation from seasonal norm\n",
    "    ny_weather[f'{feature}_seasonal_deviation'] = ny_weather[feature] - ny_weather[f'{feature}_seasonal_avg']\n",
    "\n",
    "# Handle specific seasonal anomalies\n",
    "# Create seasonal volatility measure (how unusual is current weather for this time of year?)\n",
    "for feature in ['temperature_2m_mean', 'precipitation_sum']:\n",
    "    # Calculate multi-year seasonal standard deviation for each day of year\n",
    "    seasonal_std = ny_weather.groupby('day_of_year')[feature].transform('std')\n",
    "    ny_weather[f'{feature}_seasonal_volatility'] = seasonal_std\n",
    "    \n",
    "    # Calculate z-score compared to seasonal norm (how many standard deviations from normal?)\n",
    "    ny_weather[f'{feature}_seasonal_zscore'] = (\n",
    "        (ny_weather[feature] - ny_weather[f'{feature}_seasonal_avg']) / \n",
    "        ny_weather[f'{feature}_seasonal_volatility']\n",
    "    ).fillna(0)  # Handle division by zero\n",
    "\n",
    "# Identify extreme seasonal anomalies (more than 2 standard deviations from seasonal norm)\n",
    "ny_weather['extreme_temp_anomaly'] = (\n",
    "    (ny_weather['temperature_2m_mean_seasonal_zscore'].abs() > 2)\n",
    ").astype(int)\n",
    "\n",
    "ny_weather['extreme_precip_anomaly'] = (\n",
    "    (ny_weather['precipitation_sum_seasonal_zscore'].abs() > 2)\n",
    ").astype(int)\n",
    "\n",
    "# Show examples of some extreme seasonal anomalies\n",
    "extreme_examples = ny_weather[ny_weather['extreme_temp_anomaly'] == 1].sample(min(5, sum(ny_weather['extreme_temp_anomaly'])))\n",
    "print(\"Examples of extreme temperature anomalies:\")\n",
    "print(extreme_examples[['Date', 'temperature_2m_mean', 'temperature_2m_mean_seasonal_avg', \n",
    "                 'temperature_2m_mean_seasonal_zscore', 'season_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8edf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering weather features...\n",
      "Weather features created. Total features: 49\n",
      "New weather features examples: ['month', 'day_of_year', 'season', 'season_name', 'temperature_2m_mean_seasonal_avg']\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Engineer additional weather features\n",
    "print(\"Engineering weather features...\")\n",
    "# Temperature features\n",
    "ny_weather['temp_range'] = ny_weather['temperature_2m_max'] - ny_weather['temperature_2m_min']\n",
    "ny_weather['extreme_heat'] = (ny_weather['temperature_2m_max'] > 30).astype(int)\n",
    "ny_weather['extreme_cold'] = (ny_weather['temperature_2m_min'] < 0).astype(int)\n",
    "\n",
    "# Precipitation features\n",
    "ny_weather['heavy_rain'] = (ny_weather['rain_sum'] > 10).astype(int)\n",
    "ny_weather['snow_day'] = (ny_weather['snowfall_sum'] > 0).astype(int)\n",
    "ny_weather['any_precipitation'] = (ny_weather['precipitation_sum'] > 0).astype(int)\n",
    "\n",
    "# Wind features\n",
    "ny_weather['strong_wind'] = (ny_weather['wind_gusts_10m_max'] > 40).astype(int)\n",
    "\n",
    "# Sunshine and daylight features\n",
    "ny_weather['sunshine_ratio'] = ny_weather['sunshine_duration'] / ny_weather['daylight_duration']\n",
    "ny_weather['sunshine_ratio'] = ny_weather['sunshine_ratio'].fillna(0)  # Handle division by zero\n",
    "\n",
    "# Add lag features (previous day's weather)\n",
    "for feature in ['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max']:\n",
    "    ny_weather[f'{feature}_lag1'] = ny_weather[feature].shift(1)\n",
    "    ny_weather[f'{feature}_lag2'] = ny_weather[feature].shift(2)\n",
    "    ny_weather[f'{feature}_lag3'] = ny_weather[feature].shift(3)\n",
    "\n",
    "# Add rolling statistics for temperature patterns\n",
    "for window in [3, 7]:\n",
    "    ny_weather[f'temp_mean_rolling{window}'] = ny_weather['temperature_2m_mean'].rolling(window=window).mean()\n",
    "    ny_weather[f'temp_std_rolling{window}'] = ny_weather['temperature_2m_mean'].rolling(window=window).std()\n",
    "\n",
    "# Calculate weather changes\n",
    "ny_weather['temp_change'] = ny_weather['temperature_2m_mean'].diff()\n",
    "ny_weather['rain_change'] = ny_weather['rain_sum'].diff()\n",
    "\n",
    "# Fill NaN values created by shifts and rolling calculations\n",
    "ny_weather = ny_weather.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Display the newly created features\n",
    "print(\"Weather features created. Total features:\", len(ny_weather.columns))\n",
    "new_weather_features = [col for col in ny_weather.columns if col not in ['Date'] + weather_features]\n",
    "print(\"New weather features examples:\", new_weather_features[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f20d31",
   "metadata": {},
   "source": [
    "## Handling Seasonality\n",
    "adding seasoal features to capture known market seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e447f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding seasonal features to stock data...\n",
      "Stock data with seasonal features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>quarter</th>\n",
       "      <th>january_effect</th>\n",
       "      <th>summer_doldrums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  month  season  quarter  january_effect  summer_doldrums\n",
       "0 2013-01-02      1       1        1               1                0\n",
       "1 2013-01-03      1       1        1               1                0\n",
       "2 2013-01-04      1       1        1               1                0\n",
       "3 2013-01-07      1       1        1               1                0\n",
       "4 2013-01-08      1       1        1               1                0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6: Handle Seasonality in Stock Data\n",
    "print(\"Adding seasonal features to stock data...\")\n",
    "stock_data['month'] = stock_data['Date'].dt.month\n",
    "stock_data['day_of_year'] = stock_data['Date'].dt.dayofyear\n",
    "stock_data['season'] = np.ceil(stock_data['month']/3).astype(int)\n",
    "stock_data['season'] = stock_data['season'].replace({5:1})  # Fix any values over 4\n",
    "stock_data['quarter'] = stock_data['Date'].dt.quarter\n",
    "stock_data['year'] = stock_data['Date'].dt.year\n",
    "\n",
    "# Standard seasonal stock market effects\n",
    "stock_data['january_effect'] = (stock_data['month'] == 1).astype(int)\n",
    "stock_data['december_effect'] = (stock_data['month'] == 12).astype(int)\n",
    "stock_data['october_effect'] = (stock_data['month'] == 10).astype(int)\n",
    "stock_data['summer_doldrums'] = ((stock_data['month'] >= 6) & (stock_data['month'] <= 8)).astype(int)\n",
    "stock_data['quarter_end'] = stock_data['month'].isin([3, 6, 9, 12]).astype(int)\n",
    "stock_data['day_of_week'] = stock_data['Date'].dt.dayofweek\n",
    "stock_data['is_monday'] = (stock_data['day_of_week'] == 0).astype(int)\n",
    "stock_data['is_friday'] = (stock_data['day_of_week'] == 4).astype(int)\n",
    "\n",
    "# Display some samples to verify\n",
    "print(\"Stock data with seasonal features:\")\n",
    "stock_data[['Date', 'month', 'season', 'quarter', 'january_effect', 'summer_doldrums']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9230662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging stock and weather data...\n",
      "Converting dates to date-only format...\n",
      "Stock data date range: 2010-01-04 to 2024-12-20\n",
      "Weather data date range: 2000-02-02 to 2025-02-02\n",
      "Number of overlapping dates: 3768\n",
      "Filtered stock data shape: (617824, 44)\n",
      "Filtered weather data shape: (3768, 50)\n",
      "Weather data after aggregating to daily: (3768, 49)\n",
      "Combined data shape: (617824, 92)\n",
      "Number of unique dates: 3768\n",
      "Date range of combined data: 2010-01-04 to 2024-12-20\n",
      "Number of unique stocks: 172\n",
      "Number of seasons represented: 4\n",
      "\n",
      "Sample of combined data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ema15</th>\n",
       "      <th>ema50</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m_max_lag1</th>\n",
       "      <th>wind_speed_10m_max_lag2</th>\n",
       "      <th>wind_speed_10m_max_lag3</th>\n",
       "      <th>temp_mean_rolling3</th>\n",
       "      <th>temp_std_rolling3</th>\n",
       "      <th>temp_mean_rolling7</th>\n",
       "      <th>temp_std_rolling7</th>\n",
       "      <th>temp_change</th>\n",
       "      <th>rain_change</th>\n",
       "      <th>season_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>21.629181</td>\n",
       "      <td>35.119999</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>34.099998</td>\n",
       "      <td>34.919998</td>\n",
       "      <td>13767900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19.134260</td>\n",
       "      <td>18.204042</td>\n",
       "      <td>29.515608</td>\n",
       "      <td>-1.792444</td>\n",
       "      <td>2.626080</td>\n",
       "      <td>-0.904250</td>\n",
       "      <td>2.289725</td>\n",
       "      <td>-5.243750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>21.450581</td>\n",
       "      <td>34.830002</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>34.160000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>16739300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.263872</td>\n",
       "      <td>19.134260</td>\n",
       "      <td>18.204042</td>\n",
       "      <td>-2.748000</td>\n",
       "      <td>3.023878</td>\n",
       "      <td>-1.938476</td>\n",
       "      <td>1.976605</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>21.179594</td>\n",
       "      <td>34.389999</td>\n",
       "      <td>34.889999</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>34.619999</td>\n",
       "      <td>21372100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.039999</td>\n",
       "      <td>16.263872</td>\n",
       "      <td>19.134260</td>\n",
       "      <td>-3.500778</td>\n",
       "      <td>1.720034</td>\n",
       "      <td>-2.025679</td>\n",
       "      <td>1.936430</td>\n",
       "      <td>2.972917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Symbol  Adj Close      Close       High        Low       Open  \\\n",
       "0 2013-01-02   ABBV  21.629181  35.119999  35.400002  34.099998  34.919998   \n",
       "1 2013-01-03   ABBV  21.450581  34.830002  35.000000  34.160000  35.000000   \n",
       "2 2013-01-04   ABBV  21.179594  34.389999  34.889999  34.250000  34.619999   \n",
       "\n",
       "       Volume  ema15  ema50  ...  wind_speed_10m_max_lag1  \\\n",
       "0  13767900.0    NaN    NaN  ...                19.134260   \n",
       "1  16739300.0    NaN    NaN  ...                16.263872   \n",
       "2  21372100.0    NaN    NaN  ...                14.039999   \n",
       "\n",
       "   wind_speed_10m_max_lag2  wind_speed_10m_max_lag3  temp_mean_rolling3  \\\n",
       "0                18.204042                29.515608           -1.792444   \n",
       "1                19.134260                18.204042           -2.748000   \n",
       "2                16.263872                19.134260           -3.500778   \n",
       "\n",
       "   temp_std_rolling3  temp_mean_rolling7  temp_std_rolling7  temp_change  \\\n",
       "0           2.626080           -0.904250           2.289725    -5.243750   \n",
       "1           3.023878           -1.938476           1.976605     0.012499   \n",
       "2           1.720034           -2.025679           1.936430     2.972917   \n",
       "\n",
       "   rain_change  season_name  \n",
       "0          0.0       Winter  \n",
       "1          0.0       Winter  \n",
       "2          0.0       Winter  \n",
       "\n",
       "[3 rows x 92 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: Merge stock data with weather data\n",
    "print(\"Merging stock and weather data...\")\n",
    "\n",
    "# 1. Convert dates to date-only format by extracting just the date part (year, month, day)\n",
    "print(\"Converting dates to date-only format...\")\n",
    "stock_data['Date_Only'] = pd.to_datetime(stock_data['Date']).dt.date\n",
    "ny_weather['Date_Only'] = pd.to_datetime(ny_weather['Date']).dt.date\n",
    "\n",
    "# 2. Check date ranges to understand overlap\n",
    "print(f\"Stock data date range: {min(stock_data['Date_Only'])} to {max(stock_data['Date_Only'])}\")\n",
    "print(f\"Weather data date range: {min(ny_weather['Date_Only'])} to {max(ny_weather['Date_Only'])}\")\n",
    "\n",
    "# 3. Find overlapping dates\n",
    "stock_dates = set(stock_data['Date_Only'])\n",
    "weather_dates = set(ny_weather['Date_Only'])\n",
    "overlapping_dates = stock_dates.intersection(weather_dates)\n",
    "print(f\"Number of overlapping dates: {len(overlapping_dates)}\")\n",
    "\n",
    "# 4. Filter both datasets to only use overlapping dates\n",
    "stock_data_filtered = stock_data[stock_data['Date_Only'].isin(overlapping_dates)]\n",
    "weather_data_filtered = ny_weather[ny_weather['Date_Only'].isin(overlapping_dates)]\n",
    "\n",
    "print(f\"Filtered stock data shape: {stock_data_filtered.shape}\")\n",
    "print(f\"Filtered weather data shape: {weather_data_filtered.shape}\")\n",
    "\n",
    "# 5. For weather data with multiple observations per day, take the daily average\n",
    "weather_daily = weather_data_filtered.groupby('Date_Only').mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Also preserve non-numeric columns that we want to keep\n",
    "for col in ['season', 'season_name']:\n",
    "    if col in weather_data_filtered.columns:\n",
    "        # Take the most common value for categorical data\n",
    "        weather_daily[col] = weather_data_filtered.groupby('Date_Only')[col].first().values\n",
    "\n",
    "print(f\"Weather data after aggregating to daily: {weather_daily.shape}\")\n",
    "\n",
    "# 6. Merge using the date-only column\n",
    "combined_df = pd.merge(stock_data_filtered, weather_daily, on='Date_Only', suffixes=('', '_weather'))\n",
    "print(f\"Combined data shape: {combined_df.shape}\")\n",
    "\n",
    "# 7. Add seasonal features if not present\n",
    "if 'season' not in combined_df.columns:\n",
    "    print(\"Adding season information to combined data...\")\n",
    "    combined_df['month'] = combined_df['Date'].dt.month\n",
    "    combined_df['season'] = np.ceil(combined_df['month']/3).astype(int)\n",
    "    combined_df['season'] = combined_df['season'].replace({5:1})  # Fix any values over 4\n",
    "    \n",
    "    # Map seasons to names for easier interpretation\n",
    "    season_map = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "    combined_df['season_name'] = combined_df['season'].map(season_map)\n",
    "\n",
    "# 8. Basic statistics on the merged dataset\n",
    "if not combined_df.empty:\n",
    "    print(f\"Number of unique dates: {combined_df['Date_Only'].nunique()}\")\n",
    "    print(f\"Date range of combined data: {combined_df['Date_Only'].min()} to {combined_df['Date_Only'].max()}\")\n",
    "    print(f\"Number of unique stocks: {combined_df['Ticker'].nunique()}\")\n",
    "    print(f\"Number of seasons represented: {combined_df['season'].nunique()}\")\n",
    "\n",
    "    # 9. Show sample results\n",
    "    print(\"\\nSample of combined data:\")\n",
    "    display(combined_df.head(3))\n",
    "else:\n",
    "    print(\"Combined dataframe is empty. Check date ranges for possible issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b624317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating weather-seasonality interaction features...\n",
      "Creating features for season 1 with 150244 rows\n",
      "Creating features for season 2 with 155029 rows\n",
      "Creating features for season 3 with 156982 rows\n",
      "Creating features for season 4 with 155569 rows\n",
      "Interaction features created.\n",
      "Combined data now has 100 columns\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Create interaction features between weather and stock seasonality\n",
    "print(\"Creating weather-seasonality interaction features...\")\n",
    "\n",
    "# Verify that required columns exist before proceeding\n",
    "required_columns = ['season', 'temperature_2m_mean', 'precipitation_sum']\n",
    "missing_columns = [col for col in required_columns if col not in combined_df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"Warning: Missing required columns: {missing_columns}\")\n",
    "    print(\"Available columns:\", combined_df.columns.tolist())\n",
    "    print(\"Skipping interaction feature creation.\")\n",
    "else:\n",
    "    # For each season, create season-specific weather anomaly features\n",
    "    for season in range(1, 5):\n",
    "        season_data = combined_df[combined_df['season'] == season]\n",
    "        if len(season_data) > 0:\n",
    "            print(f\"Creating features for season {season} with {len(season_data)} rows\")\n",
    "            # Calculate season-specific weather anomalies\n",
    "            for feature in ['temperature_2m_mean', 'precipitation_sum']:\n",
    "                season_avg = season_data[feature].mean()\n",
    "                season_std = season_data[feature].std()\n",
    "                # Handle case where std is 0 to avoid division by zero\n",
    "                if season_std > 0:\n",
    "                    combined_df.loc[combined_df['season'] == season, f'{feature}_season{season}_zscore'] = (\n",
    "                        (combined_df.loc[combined_df['season'] == season, feature] - season_avg) / season_std\n",
    "                    ).fillna(0)\n",
    "                else:\n",
    "                    combined_df.loc[combined_df['season'] == season, f'{feature}_season{season}_zscore'] = 0\n",
    "    \n",
    "    # Create industry-specific seasonal features if 'Sector' column exists\n",
    "    if 'Sector' in combined_df.columns:\n",
    "        print(\"Creating sector-specific seasonal features...\")\n",
    "        # Create sector-season interaction features\n",
    "        for season in range(1, 5):\n",
    "            combined_df[f'season_{season}_flag'] = (combined_df['season'] == season).astype(int)\n",
    "            \n",
    "        # For each sector, create sector-season interaction terms\n",
    "        sectors = combined_df['Sector'].unique()\n",
    "        for sector in sectors:\n",
    "            sector_mask = (combined_df['Sector'] == sector).astype(int)\n",
    "            for season in range(1, 5):\n",
    "                season_mask = (combined_df['season'] == season).astype(int)\n",
    "                combined_df[f'{sector}_season_{season}'] = sector_mask * season_mask\n",
    "    \n",
    "    print(\"Interaction features created.\")\n",
    "    print(f\"Combined data now has {combined_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0015dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature sets...\n",
      "Number of stock features: 39\n",
      "Number of weather features: 55\n",
      "Total number of features: 94\n",
      "Preparing data for modeling...\n",
      "Target value counts:\n",
      "Target\n",
      "1    321555\n",
      "0    296269\n",
      "Name: count, dtype: int64\n",
      "X_base data types: float64    26\n",
      "int32      13\n",
      "Name: count, dtype: int64\n",
      "X_all data types: float64    80\n",
      "int32      14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample stock features: ['Adj Close', 'Close', 'High', 'Low', 'Open']\n",
      "\n",
      "Sample weather features: ['temperature_2m_mean', 'temperature_2m_max', 'temperature_2m_min', 'wind_speed_10m_max', 'wind_gusts_10m_max']\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Define feature sets for comparison\n",
    "print(\"Preparing feature sets...\")\n",
    "# Exclude these columns from features\n",
    "exclude_cols = ['Date', 'Date_Only', 'Ticker', 'Symbol', 'Target', 'location', 'season_name']\n",
    "\n",
    "# Also explicitly exclude any datetime or date columns\n",
    "date_cols = combined_df.select_dtypes(include=['datetime64', 'datetime64[ns]']).columns.tolist()\n",
    "# Add any other columns that might be problematic\n",
    "obj_cols = combined_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Add all excluded columns together\n",
    "all_exclude_cols = exclude_cols + date_cols + obj_cols\n",
    "\n",
    "# Get stock features (including stock seasonality features)\n",
    "base_features = [col for col in stock_data.columns \n",
    "                 if col not in all_exclude_cols \n",
    "                 and col in combined_df.columns  # Make sure feature exists in combined dataframe\n",
    "                 and pd.api.types.is_numeric_dtype(combined_df[col])]  # Only include numeric columns\n",
    "\n",
    "# Get weather-only features (including weather seasonality features)\n",
    "weather_only_features = [col for col in combined_df.columns \n",
    "                        if col not in stock_data.columns \n",
    "                        and col not in all_exclude_cols\n",
    "                        and pd.api.types.is_numeric_dtype(combined_df[col])]  # Only include numeric columns\n",
    "\n",
    "# Get all features\n",
    "all_features = base_features + weather_only_features\n",
    "\n",
    "# Print feature counts\n",
    "print(f\"Number of stock features: {len(base_features)}\")\n",
    "print(f\"Number of weather features: {len(weather_only_features)}\")\n",
    "print(f\"Total number of features: {len(all_features)}\")\n",
    "\n",
    "# Prepare data for modeling\n",
    "print(\"Preparing data for modeling...\")\n",
    "# Check target variable\n",
    "print(\"Target value counts:\")\n",
    "print(combined_df['Target'].value_counts())\n",
    "\n",
    "# Make sure the target is properly encoded as 0/1\n",
    "combined_df['Target'] = combined_df['Target'].astype(int)\n",
    "\n",
    "y = combined_df['Target']\n",
    "X_base = combined_df[base_features]\n",
    "X_all = combined_df[all_features]\n",
    "\n",
    "# Verify that we only have numeric data\n",
    "print(f\"X_base data types: {X_base.dtypes.value_counts()}\")\n",
    "print(f\"X_all data types: {X_all.dtypes.value_counts()}\")\n",
    "\n",
    "# Display first few features of each type\n",
    "print(\"\\nSample stock features:\", base_features[:5])\n",
    "print(\"\\nSample weather features:\", weather_only_features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9212a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Updated function to evaluate models with different feature sets\n",
    "def evaluate_model(X, y, feature_set_name):\n",
    "    print(f\"Input data shapes: X={X.shape}, y={y.shape}\")\n",
    "    \n",
    "    # Make sure we only include numeric features\n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "    if len(numeric_columns) < X.shape[1]:\n",
    "        print(f\"Warning: Dropping {X.shape[1] - len(numeric_columns)} non-numeric columns\")\n",
    "        X = X[numeric_columns]\n",
    "    \n",
    "    # Check target values\n",
    "    print(\"Target value counts:\")\n",
    "    print(y.value_counts())\n",
    "    \n",
    "    # Convert target to int\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train a Random Forest (better than Decision Tree for this task)\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=20,\n",
    "        min_samples_leaf=4,\n",
    "        min_samples_split=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "    \n",
    "    print(f\"Training {feature_set_name} model...\")\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = rf.predict(X_test_scaled)\n",
    "    y_pred_proba = rf.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Advanced metrics\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    pr_auc = average_precision_score(y_test, y_pred_proba)\n",
    "    log_loss_score = log_loss(y_test, y_pred_proba)\n",
    "    brier = brier_score_loss(y_test, y_pred_proba)\n",
    "    \n",
    "    # Calculate feature importance using the model's built-in importance\n",
    "    feature_imp = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': rf.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\n--- {feature_set_name} Model Results ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "    print(f\"Log Loss: {log_loss_score:.4f}\")\n",
    "    print(f\"Brier Score: {brier:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop 10 Important Features:\")\n",
    "    print(feature_imp.head(10))\n",
    "    \n",
    "    # Calculate confusion matrix for better understanding\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {feature_set_name}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(weather_data_dir, f'{feature_set_name.replace(\" \", \"_\").lower()}_confusion_matrix.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Return model, metrics, and feature importance\n",
    "    metrics_dict = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'log_loss': log_loss_score,\n",
    "        'brier_score': brier\n",
    "    }\n",
    "    \n",
    "    return rf, metrics_dict, feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c13988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating base model (stock data only)...\n",
      "Input data shapes: X=(617824, 39), y=(617824,)\n",
      "Target value counts:\n",
      "Target\n",
      "1    321555\n",
      "0    296269\n",
      "Name: count, dtype: int64\n",
      "Training Base Model (Stock Data Only) model...\n",
      "\n",
      "--- Base Model (Stock Data Only) Model Results ---\n",
      "Accuracy: 0.6123\n",
      "Precision: 0.5986\n",
      "Recall: 0.7806\n",
      "F1 Score: 0.6776\n",
      "ROC-AUC: 0.6630\n",
      "PR-AUC: 0.6732\n",
      "Log Loss: 0.6644\n",
      "Brier Score: 0.2360\n",
      "\n",
      "Top 10 Important Features:\n",
      "        Feature  Importance\n",
      "27  day_of_year    0.088963\n",
      "23         Log5    0.046158\n",
      "20       Clopen    0.045375\n",
      "19       roc_10    0.043077\n",
      "21      HighLow    0.042909\n",
      "24        Log15    0.042007\n",
      "14      stoch_k    0.041432\n",
      "15      stoch_d    0.041363\n",
      "25        Log30    0.040607\n",
      "13          rsi    0.040016\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Evaluate base model (stock data only) - Modified to avoid CSV saving\n",
    "print(\"\\nEvaluating base model (stock data only)...\")\n",
    "base_model, base_metrics, base_importance = evaluate_model(X_base, y, \"Base Model (Stock Data Only)\")\n",
    "\n",
    "# Visualize base model feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=base_importance.head(15))\n",
    "plt.title('Top 15 Features (Stock Data Only Model)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(weather_data_dir, 'base_feature_importance.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17993c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating combined model (stock + weather)...\n",
      "Input data shapes: X=(617824, 94), y=(617824,)\n",
      "Target value counts:\n",
      "Target\n",
      "1    321555\n",
      "0    296269\n",
      "Name: count, dtype: int64\n",
      "Training Combined Model (Stock + Weather) model...\n",
      "\n",
      "--- Combined Model (Stock + Weather) Model Results ---\n",
      "Accuracy: 0.7076\n",
      "Precision: 0.6927\n",
      "Recall: 0.7902\n",
      "F1 Score: 0.7383\n",
      "ROC-AUC: 0.7790\n",
      "PR-AUC: 0.7786\n",
      "Log Loss: 0.5956\n",
      "Brier Score: 0.2039\n",
      "\n",
      "Top 10 Important Features:\n",
      "                    Feature  Importance\n",
      "42       wind_speed_10m_max    0.020321\n",
      "78  wind_speed_10m_max_lag2    0.019868\n",
      "77  wind_speed_10m_max_lag1    0.019764\n",
      "84              temp_change    0.019116\n",
      "83        temp_std_rolling7    0.019107\n",
      "81        temp_std_rolling3    0.018891\n",
      "23                     Log5    0.018555\n",
      "49        daylight_duration    0.018501\n",
      "79  wind_speed_10m_max_lag3    0.018464\n",
      "20                   Clopen    0.018342\n",
      "\n",
      "Weather features in top 20 important features:\n",
      "['wind_speed_10m_max', 'wind_speed_10m_max_lag2', 'wind_speed_10m_max_lag1', 'temp_change', 'temp_std_rolling7', 'temp_std_rolling3', 'daylight_duration', 'wind_speed_10m_max_lag3', 'temp_range', 'precipitation_sum_seasonal_volatility', 'temperature_2m_mean_seasonal_deviation']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 12: Evaluate combined model (stock + weather) - Modified to avoid CSV saving\n",
    "print(\"\\nEvaluating combined model (stock + weather)...\")\n",
    "all_model, all_metrics, all_importance = evaluate_model(X_all, y, \"Combined Model (Stock + Weather)\")\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=all_importance.head(15))\n",
    "plt.title('Top 15 Features (Stock + Weather Model)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(weather_data_dir, 'feature_importance.png'))\n",
    "plt.close()\n",
    "\n",
    "# Weather features in the top features\n",
    "weather_in_top = [feature for feature in all_importance.head(20)['Feature'] \n",
    "                 if feature in weather_only_features]\n",
    "print(\"\\nWeather features in top 20 important features:\")\n",
    "print(weather_in_top)\n",
    "\n",
    "# Create ROC curve comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "from sklearn.metrics import roc_curve\n",
    "# Function to plot ROC curves for both models\n",
    "def plot_roc_comparison(X_base, X_all, y, base_model, all_model):\n",
    "    # Get test data\n",
    "    _, X_test_base, _, y_test = train_test_split(X_base, y, test_size=0.25, random_state=42)\n",
    "    _, X_test_all, _, _ = train_test_split(X_all, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # Scale test data\n",
    "    scaler_base = StandardScaler()\n",
    "    scaler_all = StandardScaler()\n",
    "    X_test_base_scaled = scaler_base.fit_transform(X_test_base)\n",
    "    X_test_all_scaled = scaler_all.fit_transform(X_test_all)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_base = base_model.predict_proba(X_test_base_scaled)[:, 1]\n",
    "    y_pred_all = all_model.predict_proba(X_test_all_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate ROC\n",
    "    fpr_base, tpr_base, _ = roc_curve(y_test, y_pred_base)\n",
    "    fpr_all, tpr_all, _ = roc_curve(y_test, y_pred_all)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr_base, tpr_base, label=f'Base Model (AUC = {base_metrics[\"roc_auc\"]:.4f})')\n",
    "    plt.plot(fpr_all, tpr_all, label=f'Combined Model (AUC = {all_metrics[\"roc_auc\"]:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(weather_data_dir, 'roc_curve_comparison.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Plot ROC curve comparison\n",
    "plot_roc_comparison(X_base, X_all, y, base_model, all_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55de8ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating seasonality-specific models...\n",
      "\n",
      "Evaluating Winter model...\n",
      "Input data shapes: X=(150244, 94), y=(150244,)\n",
      "Target value counts:\n",
      "Target\n",
      "1    79323\n",
      "0    70921\n",
      "Name: count, dtype: int64\n",
      "Training Winter Model model...\n",
      "\n",
      "--- Winter Model Model Results ---\n",
      "Accuracy: 0.7139\n",
      "Precision: 0.7123\n",
      "Recall: 0.7633\n",
      "F1 Score: 0.7369\n",
      "ROC-AUC: 0.7912\n",
      "PR-AUC: 0.7996\n",
      "Log Loss: 0.5491\n",
      "Brier Score: 0.1858\n",
      "\n",
      "Top 10 Important Features:\n",
      "        Feature  Importance\n",
      "25        Log30    0.024958\n",
      "23         Log5    0.024717\n",
      "21      HighLow    0.024226\n",
      "24        Log15    0.023773\n",
      "20       Clopen    0.023755\n",
      "19       roc_10    0.023442\n",
      "8          macd    0.023185\n",
      "14      stoch_k    0.023081\n",
      "13          rsi    0.022651\n",
      "9   macd_signal    0.022378\n",
      "\n",
      "Evaluating Spring model...\n",
      "Input data shapes: X=(155029, 94), y=(155029,)\n",
      "Target value counts:\n",
      "Target\n",
      "1    80371\n",
      "0    74658\n",
      "Name: count, dtype: int64\n",
      "Training Spring Model model...\n",
      "\n",
      "--- Spring Model Model Results ---\n",
      "Accuracy: 0.7200\n",
      "Precision: 0.7108\n",
      "Recall: 0.7707\n",
      "F1 Score: 0.7395\n",
      "ROC-AUC: 0.7960\n",
      "PR-AUC: 0.7945\n",
      "Log Loss: 0.5468\n",
      "Brier Score: 0.1846\n",
      "\n",
      "Top 10 Important Features:\n",
      "              Feature  Importance\n",
      "20             Clopen    0.022175\n",
      "23               Log5    0.022044\n",
      "21            HighLow    0.021160\n",
      "25              Log30    0.020931\n",
      "24              Log15    0.020492\n",
      "14            stoch_k    0.020488\n",
      "19             roc_10    0.020482\n",
      "81  temp_std_rolling3    0.020366\n",
      "9         macd_signal    0.020007\n",
      "15            stoch_d    0.020002\n",
      "\n",
      "Evaluating Summer model...\n",
      "Input data shapes: X=(156982, 94), y=(156982,)\n",
      "Target value counts:\n",
      "Target\n",
      "1    80004\n",
      "0    76978\n",
      "Name: count, dtype: int64\n",
      "Training Summer Model model...\n",
      "\n",
      "--- Summer Model Model Results ---\n",
      "Accuracy: 0.7111\n",
      "Precision: 0.7157\n",
      "Recall: 0.7185\n",
      "F1 Score: 0.7171\n",
      "ROC-AUC: 0.7884\n",
      "PR-AUC: 0.7891\n",
      "Log Loss: 0.5564\n",
      "Brier Score: 0.1885\n",
      "\n",
      "Top 10 Important Features:\n",
      "        Feature  Importance\n",
      "20       Clopen    0.023463\n",
      "23         Log5    0.022617\n",
      "21      HighLow    0.022065\n",
      "25        Log30    0.021902\n",
      "24        Log15    0.021871\n",
      "19       roc_10    0.021425\n",
      "13          rsi    0.020874\n",
      "9   macd_signal    0.020622\n",
      "14      stoch_k    0.020617\n",
      "15      stoch_d    0.020528\n",
      "\n",
      "Evaluating Fall model...\n",
      "Input data shapes: X=(155569, 94), y=(155569,)\n",
      "Target value counts:\n",
      "Target\n",
      "1    81857\n",
      "0    73712\n",
      "Name: count, dtype: int64\n",
      "Training Fall Model model...\n",
      "\n",
      "--- Fall Model Model Results ---\n",
      "Accuracy: 0.7116\n",
      "Precision: 0.7158\n",
      "Recall: 0.7544\n",
      "F1 Score: 0.7346\n",
      "ROC-AUC: 0.7884\n",
      "PR-AUC: 0.8017\n",
      "Log Loss: 0.5518\n",
      "Brier Score: 0.1870\n",
      "\n",
      "Top 10 Important Features:\n",
      "        Feature  Importance\n",
      "23         Log5    0.023121\n",
      "20       Clopen    0.022775\n",
      "25        Log30    0.022322\n",
      "21      HighLow    0.022284\n",
      "19       roc_10    0.021873\n",
      "24        Log15    0.021524\n",
      "14      stoch_k    0.021465\n",
      "9   macd_signal    0.021229\n",
      "13          rsi    0.020966\n",
      "15      stoch_d    0.020393\n",
      "\n",
      "Seasonal Model Summary:\n",
      "\n",
      "Winter:\n",
      "  Accuracy: 0.7139\n",
      "  ROC-AUC: 0.7912\n",
      "  F1 Score: 0.7369\n",
      "  Top features: ['Log30', 'Log5', 'HighLow', 'Log15', 'Clopen']\n",
      "\n",
      "Spring:\n",
      "  Accuracy: 0.7200\n",
      "  ROC-AUC: 0.7960\n",
      "  F1 Score: 0.7395\n",
      "  Top features: ['Clopen', 'Log5', 'HighLow', 'Log30', 'Log15']\n",
      "\n",
      "Summer:\n",
      "  Accuracy: 0.7111\n",
      "  ROC-AUC: 0.7884\n",
      "  F1 Score: 0.7171\n",
      "  Top features: ['Clopen', 'Log5', 'HighLow', 'Log30', 'Log15']\n",
      "\n",
      "Fall:\n",
      "  Accuracy: 0.7116\n",
      "  ROC-AUC: 0.7884\n",
      "  F1 Score: 0.7346\n",
      "  Top features: ['Log5', 'Clopen', 'Log30', 'HighLow', 'roc_10']\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Evaluate seasonality-specific models - Modified to avoid CSV saving\n",
    "print(\"\\nEvaluating seasonality-specific models...\")\n",
    "seasons = combined_df['season'].unique()\n",
    "season_results = {}\n",
    "\n",
    "for season in seasons:\n",
    "    season_name = season_map.get(season, f\"Season {season}\")\n",
    "    print(f\"\\nEvaluating {season_name} model...\")\n",
    "    season_mask = combined_df['season'] == season\n",
    "    \n",
    "    if sum(season_mask) > 100:  # Only evaluate if enough data\n",
    "        season_X = X_all[season_mask]\n",
    "        season_y = y[season_mask]\n",
    "        \n",
    "        _, season_metrics, season_imp = evaluate_model(\n",
    "            season_X, season_y, f\"{season_name} Model\"\n",
    "        )\n",
    "        \n",
    "        season_results[season_name] = {\n",
    "            'metrics': season_metrics,\n",
    "            'top_features': season_imp.head(5)['Feature'].tolist()\n",
    "        }\n",
    "        \n",
    "        # Visualize seasonal feature importance\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=season_imp.head(10))\n",
    "        plt.title(f'Top 10 Features - {season_name} Model')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(weather_data_dir, f'{season_name}_feature_importance.png'))\n",
    "        plt.close()\n",
    "\n",
    "# Display summary of seasonal results\n",
    "print(\"\\nSeasonal Model Summary:\")\n",
    "for season, results in season_results.items():\n",
    "    print(f\"\\n{season}:\")\n",
    "    print(f\"  Accuracy: {results['metrics']['accuracy']:.4f}\")\n",
    "    print(f\"  ROC-AUC: {results['metrics']['roc_auc']:.4f}\")\n",
    "    print(f\"  F1 Score: {results['metrics']['f1']:.4f}\")\n",
    "    print(f\"  Top features: {results['top_features']}\")\n",
    "\n",
    "# Create comparison chart of seasonal metrics\n",
    "seasonal_metrics_df = pd.DataFrame({\n",
    "    'Season': [],\n",
    "    'Metric': [],\n",
    "    'Value': []\n",
    "})\n",
    "\n",
    "for season, results in season_results.items():\n",
    "    for metric_name, metric_value in results['metrics'].items():\n",
    "        seasonal_metrics_df = pd.concat([seasonal_metrics_df, pd.DataFrame({\n",
    "            'Season': [season],\n",
    "            'Metric': [metric_name],\n",
    "            'Value': [metric_value]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "# Visualize key seasonal metrics\n",
    "plt.figure(figsize=(14, 10))\n",
    "key_metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "key_metrics_df = seasonal_metrics_df[seasonal_metrics_df['Metric'].isin(key_metrics)]\n",
    "\n",
    "sns.barplot(x='Season', y='Value', hue='Metric', data=key_metrics_df)\n",
    "plt.title('Comparison of Key Metrics Across Seasons')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(weather_data_dir, 'seasonal_metrics_comparison.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0524f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing time series cross-validation...\n",
      "Using a sample of 50000 rows for cross-validation instead of 617824 total rows\n",
      "Running cross-validation (this may take some time)...\n",
      "\n",
      "Processing fold 1/3...\n",
      "Training base model...\n",
      "Base model - Accuracy: 0.5096, F1: 0.6097\n",
      "Training combined model...\n",
      "Combined model - Accuracy: 0.5623, F1: 0.6354\n",
      "Analyzing seasonal performance...\n",
      "  Season 1: Improvement: 0.0527\n",
      "  Season 2: Improvement: 0.0522\n",
      "  Season 3: Improvement: 0.0469\n",
      "  Season 4: Improvement: 0.0592\n",
      "\n",
      "Processing fold 2/3...\n",
      "Training base model...\n",
      "Base model - Accuracy: 0.5207, F1: 0.6326\n",
      "Training combined model...\n",
      "Combined model - Accuracy: 0.5964, F1: 0.6785\n",
      "Analyzing seasonal performance...\n",
      "  Season 1: Improvement: 0.0611\n",
      "  Season 2: Improvement: 0.0823\n",
      "  Season 3: Improvement: 0.0910\n",
      "  Season 4: Improvement: 0.0672\n",
      "\n",
      "Processing fold 3/3...\n",
      "Training base model...\n",
      "Base model - Accuracy: 0.5235, F1: 0.6419\n",
      "Training combined model...\n",
      "Combined model - Accuracy: 0.6090, F1: 0.6904\n",
      "Analyzing seasonal performance...\n",
      "  Season 1: Improvement: 0.0846\n",
      "  Season 2: Improvement: 0.0822\n",
      "  Season 3: Improvement: 0.0976\n",
      "  Season 4: Improvement: 0.0774\n",
      "\n",
      "--- Time Series Cross-Validation Results ---\n",
      "Base Model Avg Accuracy: 0.5179\n",
      "Combined Model Avg Accuracy: 0.5892\n",
      "Overall Improvement: 0.0713\n",
      "\n",
      "--- Detailed CV Metrics Comparison ---\n",
      "      Metric  Base Model  Combined Model  Improvement  \\\n",
      "0   accuracy    0.517947        0.589227     0.071280   \n",
      "1  precision    0.524620        0.575846     0.051226   \n",
      "2     recall    0.782913        0.796058     0.013145   \n",
      "3         f1    0.628053        0.668102     0.040048   \n",
      "4    roc_auc    0.518767        0.634184     0.115416   \n",
      "\n",
      "   Relative Improvement (%)  \n",
      "0                 13.762035  \n",
      "1                  9.764343  \n",
      "2                  1.678921  \n",
      "3                  6.376557  \n",
      "4                 22.248162  \n",
      "\n",
      "--- Seasonal Improvement Analysis ---\n",
      "Winter: 0.0661 accuracy improvement\n",
      "Spring: 0.0722 accuracy improvement\n",
      "Summer: 0.0785 accuracy improvement\n",
      "Fall: 0.0679 accuracy improvement\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Time series cross-validation - Modified to avoid CSV saving and optimize performance\n",
    "print(\"\\nPerforming time series cross-validation...\")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define a smaller number of CV splits for faster processing\n",
    "tscv = TimeSeriesSplit(n_splits=3)  # Reduced from 5 to 3\n",
    "base_cv_scores = []\n",
    "all_cv_scores = []\n",
    "seasonal_cv_scores = {1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "# Additional metrics for cross-validation\n",
    "base_cv_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'roc_auc': []}\n",
    "all_cv_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'roc_auc': []}\n",
    "\n",
    "# Get a sample of the data if it's too large\n",
    "sample_size = 50000  # Adjust based on your system capabilities\n",
    "if len(X_all) > sample_size:\n",
    "    # Use stratified sampling to maintain class balance\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    _, X_all_sample, _, y_sample = train_test_split(\n",
    "        X_all, y, test_size=sample_size/len(X_all), stratify=y, random_state=42\n",
    "    )\n",
    "    X_base_sample = X_base.loc[X_all_sample.index]\n",
    "    combined_df_sample = combined_df.loc[X_all_sample.index]\n",
    "    \n",
    "    print(f\"Using a sample of {sample_size} rows for cross-validation instead of {len(X_all)} total rows\")\n",
    "    X_all_cv = X_all_sample\n",
    "    X_base_cv = X_base_sample\n",
    "    y_cv = y_sample\n",
    "    combined_df_cv = combined_df_sample\n",
    "else:\n",
    "    X_all_cv = X_all\n",
    "    X_base_cv = X_base\n",
    "    y_cv = y\n",
    "    combined_df_cv = combined_df\n",
    "\n",
    "print(\"Running cross-validation (this may take some time)...\")\n",
    "\n",
    "# Use lighter RandomForest for CV\n",
    "rf_params = {\n",
    "    'n_estimators': 50,       # Fewer trees\n",
    "    'max_depth': 10,          # Lower depth\n",
    "    'min_samples_leaf': 10,   # More aggressive pruning\n",
    "    'min_samples_split': 20,  # More aggressive pruning\n",
    "    'max_features': 'sqrt',   # Use sqrt of features for faster training\n",
    "    'random_state': 42,\n",
    "    'n_jobs': 4,              # Limit parallel jobs\n",
    "    'verbose': 0              # No verbose output during CV\n",
    "}\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_all_cv)):\n",
    "    print(f\"\\nProcessing fold {fold+1}/{tscv.n_splits}...\")\n",
    "    \n",
    "    # Base model (stock only)\n",
    "    X_train_base, X_test_base = X_base_cv.iloc[train_idx], X_base_cv.iloc[test_idx]\n",
    "    y_train, y_test = y_cv.iloc[train_idx], y_cv.iloc[test_idx]\n",
    "    \n",
    "    # Get season info for test set\n",
    "    test_seasons = combined_df_cv.iloc[test_idx]['season'].values\n",
    "    \n",
    "    # Train base model\n",
    "    print(\"Training base model...\")\n",
    "    scaler_base = StandardScaler()\n",
    "    X_train_base_scaled = scaler_base.fit_transform(X_train_base)\n",
    "    X_test_base_scaled = scaler_base.transform(X_test_base)\n",
    "    \n",
    "    base_rf = RandomForestClassifier(**rf_params)\n",
    "    base_rf.fit(X_train_base_scaled, y_train)\n",
    "    base_preds = base_rf.predict(X_test_base_scaled)\n",
    "    \n",
    "    # Calculate basic metrics for base model\n",
    "    base_acc = accuracy_score(y_test, base_preds)\n",
    "    base_prec = precision_score(y_test, base_preds, zero_division=0)\n",
    "    base_rec = recall_score(y_test, base_preds, zero_division=0)\n",
    "    base_f1 = f1_score(y_test, base_preds, zero_division=0)\n",
    "    \n",
    "    # Get probabilities for ROC AUC - with error handling\n",
    "    try:\n",
    "        base_probs = base_rf.predict_proba(X_test_base_scaled)[:, 1]\n",
    "        base_roc_auc = roc_auc_score(y_test, base_probs)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not calculate ROC AUC for base model: {e}\")\n",
    "        base_roc_auc = float('nan')\n",
    "    \n",
    "    # Store base model metrics\n",
    "    base_cv_scores.append(base_acc)\n",
    "    base_cv_metrics['accuracy'].append(base_acc)\n",
    "    base_cv_metrics['precision'].append(base_prec)\n",
    "    base_cv_metrics['recall'].append(base_rec)\n",
    "    base_cv_metrics['f1'].append(base_f1)\n",
    "    base_cv_metrics['roc_auc'].append(base_roc_auc)\n",
    "    \n",
    "    print(f\"Base model - Accuracy: {base_acc:.4f}, F1: {base_f1:.4f}\")\n",
    "    \n",
    "    # Combined model (stock + weather)\n",
    "    print(\"Training combined model...\")\n",
    "    X_train_all, X_test_all = X_all_cv.iloc[train_idx], X_all_cv.iloc[test_idx]\n",
    "    \n",
    "    scaler_all = StandardScaler()\n",
    "    X_train_all_scaled = scaler_all.fit_transform(X_train_all)\n",
    "    X_test_all_scaled = scaler_all.transform(X_test_all)\n",
    "    \n",
    "    all_rf = RandomForestClassifier(**rf_params)\n",
    "    all_rf.fit(X_train_all_scaled, y_train)\n",
    "    all_preds = all_rf.predict(X_test_all_scaled)\n",
    "    \n",
    "    # Calculate metrics for combined model\n",
    "    all_acc = accuracy_score(y_test, all_preds)\n",
    "    all_prec = precision_score(y_test, all_preds, zero_division=0)\n",
    "    all_rec = recall_score(y_test, all_preds, zero_division=0)\n",
    "    all_f1 = f1_score(y_test, all_preds, zero_division=0)\n",
    "    \n",
    "    # Get probabilities for ROC AUC - with error handling\n",
    "    try:\n",
    "        all_probs = all_rf.predict_proba(X_test_all_scaled)[:, 1]\n",
    "        all_roc_auc = roc_auc_score(y_test, all_probs)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not calculate ROC AUC for combined model: {e}\")\n",
    "        all_roc_auc = float('nan')\n",
    "    \n",
    "    # Store combined model metrics\n",
    "    all_cv_scores.append(all_acc)\n",
    "    all_cv_metrics['accuracy'].append(all_acc)\n",
    "    all_cv_metrics['precision'].append(all_prec)\n",
    "    all_cv_metrics['recall'].append(all_rec)\n",
    "    all_cv_metrics['f1'].append(all_f1)\n",
    "    all_cv_metrics['roc_auc'].append(all_roc_auc)\n",
    "    \n",
    "    print(f\"Combined model - Accuracy: {all_acc:.4f}, F1: {all_f1:.4f}\")\n",
    "    \n",
    "    # Calculate seasonal performance\n",
    "    print(\"Analyzing seasonal performance...\")\n",
    "    for season in range(1, 5):\n",
    "        season_mask = test_seasons == season\n",
    "        if np.sum(season_mask) > 0:\n",
    "            season_y_test = y_test.iloc[season_mask] if isinstance(y_test, pd.Series) else y_test[season_mask]\n",
    "            season_base_preds = base_preds[season_mask]\n",
    "            season_all_preds = all_preds[season_mask]\n",
    "            \n",
    "            # Compare performance improvement by season\n",
    "            if len(season_y_test) > 0:\n",
    "                try:\n",
    "                    base_season_acc = accuracy_score(season_y_test, season_base_preds)\n",
    "                    all_season_acc = accuracy_score(season_y_test, season_all_preds)\n",
    "                    seasonal_cv_scores[season].append(all_season_acc - base_season_acc)\n",
    "                    print(f\"  Season {season}: Improvement: {all_season_acc - base_season_acc:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error calculating season {season} metrics: {e}\")\n",
    "\n",
    "print(\"\\n--- Time Series Cross-Validation Results ---\")\n",
    "print(f\"Base Model Avg Accuracy: {np.mean(base_cv_scores):.4f}\")\n",
    "print(f\"Combined Model Avg Accuracy: {np.mean(all_cv_scores):.4f}\")\n",
    "print(f\"Overall Improvement: {np.mean(all_cv_scores) - np.mean(base_cv_scores):.4f}\")\n",
    "\n",
    "# Create table of all CV metrics\n",
    "try:\n",
    "    cv_metrics_table = pd.DataFrame({\n",
    "        'Metric': list(base_cv_metrics.keys()),\n",
    "        'Base Model': [np.nanmean(base_cv_metrics[m]) for m in base_cv_metrics],\n",
    "        'Combined Model': [np.nanmean(all_cv_metrics[m]) for m in all_cv_metrics],\n",
    "        'Improvement': [np.nanmean(all_cv_metrics[m]) - np.nanmean(base_cv_metrics[m]) \n",
    "                    for m in base_cv_metrics]\n",
    "    })\n",
    "    \n",
    "    # Calculate relative improvement with error handling for division by zero\n",
    "    rel_imp = []\n",
    "    for m in base_cv_metrics.keys():\n",
    "        base_val = np.nanmean(base_cv_metrics[m])\n",
    "        if base_val != 0:\n",
    "            rel_imp.append(100 * (np.nanmean(all_cv_metrics[m]) - base_val) / base_val)\n",
    "        else:\n",
    "            rel_imp.append(float('nan'))\n",
    "    \n",
    "    cv_metrics_table['Relative Improvement (%)'] = rel_imp\n",
    "    \n",
    "    print(\"\\n--- Detailed CV Metrics Comparison ---\")\n",
    "    print(cv_metrics_table)\n",
    "except Exception as e:\n",
    "    print(f\"Error creating metrics table: {e}\")\n",
    "\n",
    "# Print seasonal improvements\n",
    "print(\"\\n--- Seasonal Improvement Analysis ---\")\n",
    "for season in range(1, 5):\n",
    "    if seasonal_cv_scores[season]:\n",
    "        avg_improvement = np.mean(seasonal_cv_scores[season])\n",
    "        season_name = season_map.get(season, f\"Season {season}\")\n",
    "        print(f\"{season_name}: {avg_improvement:.4f} accuracy improvement\")\n",
    "\n",
    "# Visualize the results\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(base_cv_scores)), base_cv_scores, width=0.4, label='Stock Only', alpha=0.7)\n",
    "    plt.bar([x + 0.4 for x in range(len(all_cv_scores))], all_cv_scores, \n",
    "            width=0.4, label='Stock + Weather', alpha=0.7)\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Cross-Validation Results: Stock vs. Stock+Weather Models')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(weather_data_dir, 'cv_results.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Visualize CV metrics comparison\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    metrics_to_plot = [m for m in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'] \n",
    "                      if not np.isnan(np.nanmean(base_cv_metrics[m]))]\n",
    "    \n",
    "    x = np.arange(len(metrics_to_plot))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.bar(x - width/2, [np.nanmean(base_cv_metrics[m]) for m in metrics_to_plot], width, \n",
    "            label='Base Model')\n",
    "    plt.bar(x + width/2, [np.nanmean(all_cv_metrics[m]) for m in metrics_to_plot], width, \n",
    "            label='Combined Model')\n",
    "\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Cross-Validation Metrics Comparison')\n",
    "    plt.xticks(x, metrics_to_plot)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(weather_data_dir, 'cv_metrics_comparison.png'))\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96f324a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing seasonal impact on individual stocks...\n",
      "Analyzing ABBV...\n",
      "Analyzing ABT...\n",
      "Analyzing ADM...\n",
      "Analyzing AES...\n",
      "Analyzing AJG...\n",
      "Analyzing ALB...\n",
      "Analyzing ALL...\n",
      "Analyzing ALLE...\n",
      "Analyzing AMP...\n",
      "Analyzing AMZN...\n",
      "Analyzing ANET...\n",
      "Analyzing ANSS...\n",
      "Analyzing AOS...\n",
      "Analyzing APH...\n",
      "Analyzing AXON...\n",
      "Analyzing AXP...\n",
      "Analyzing BAX...\n",
      "Analyzing BBY...\n",
      "Analyzing BDX...\n",
      "Analyzing BEN...\n",
      "\n",
      "--- Stocks Most Affected by Weather by Season ---\n",
      "\n",
      "Winter:\n",
      "   Ticker  Season  Weather_Impact\n",
      "48    AOS  Winter        0.073913\n",
      "52    APH  Winter        0.060870\n",
      "20    ALB  Winter        0.034783\n",
      "12    AES  Winter        0.030435\n",
      "68    BBY  Winter        0.000000\n",
      "\n",
      "Spring:\n",
      "   Ticker  Season  Weather_Impact\n",
      "41   ANET  Spring        0.049383\n",
      "49    AOS  Spring        0.025316\n",
      "53    APH  Spring        0.021097\n",
      "77    BEN  Spring        0.012658\n",
      "17    AJG  Spring        0.000000\n",
      "\n",
      "Summer:\n",
      "   Ticker  Season  Weather_Impact\n",
      "14    AES  Summer        0.054393\n",
      "42   ANET  Summer        0.045455\n",
      "22    ALB  Summer        0.025105\n",
      "30   ALLE  Summer        0.017045\n",
      "58   AXON  Summer        0.008368\n",
      "\n",
      "Fall:\n",
      "   Ticker Season  Weather_Impact\n",
      "27    ALL   Fall        0.067511\n",
      "79    BEN   Fall        0.046414\n",
      "51    AOS   Fall        0.029536\n",
      "7     ABT   Fall        0.016878\n",
      "47   ANSS   Fall        0.008439\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Stock-specific seasonal analysis - Modified to avoid CSV saving\n",
    "print(\"\\nAnalyzing seasonal impact on individual stocks...\")\n",
    "seasonal_impact = {}\n",
    "unique_symbols = combined_df['Ticker'].unique()\n",
    "\n",
    "# Only process a reasonable number of stocks for demonstration\n",
    "analyze_symbols = unique_symbols[:min(20, len(unique_symbols))]\n",
    "\n",
    "for symbol in analyze_symbols:\n",
    "    symbol_data = combined_df[combined_df['Ticker'] == symbol]\n",
    "    if len(symbol_data) > 200:  # Only analyze stocks with sufficient data\n",
    "        print(f\"Analyzing {symbol}...\")\n",
    "        symbol_seasonal_impact = {}\n",
    "        \n",
    "        for season in range(1, 5):\n",
    "            season_name = season_map.get(season, f\"Season {season}\")\n",
    "            season_data = symbol_data[symbol_data['season'] == season]\n",
    "            \n",
    "            if len(season_data) > 50:  # Make sure we have enough data for this season\n",
    "                # Quick analysis of this specific stock in this season\n",
    "                try:\n",
    "                    season_X_base = season_data[base_features]\n",
    "                    season_X_all = season_data[all_features]\n",
    "                    season_y = season_data['Target']\n",
    "                    \n",
    "                    X_train, X_test, y_train, y_test = train_test_split(season_X_base, season_y, test_size=0.25)\n",
    "                    base_rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "                    base_rf.fit(X_train, y_train)\n",
    "                    base_acc = accuracy_score(y_test, base_rf.predict(X_test))\n",
    "                    \n",
    "                    X_train, X_test, y_train, y_test = train_test_split(season_X_all, season_y, test_size=0.25)\n",
    "                    all_rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "                    all_rf.fit(X_train, y_train)\n",
    "                    all_acc = accuracy_score(y_test, all_rf.predict(X_test))\n",
    "                    \n",
    "                    symbol_seasonal_impact[season_name] = all_acc - base_acc\n",
    "                except Exception as e:\n",
    "                    print(f\"Error analyzing {symbol} in {season_name}: {e}\")\n",
    "        \n",
    "        seasonal_impact[symbol] = symbol_seasonal_impact\n",
    "\n",
    "# Convert results to DataFrame for easier analysis\n",
    "seasonal_results = []\n",
    "for symbol, impacts in seasonal_impact.items():\n",
    "    for season, impact in impacts.items():\n",
    "        seasonal_results.append({\n",
    "            'Ticker': symbol,\n",
    "            'Season': season,\n",
    "            'Weather_Impact': impact\n",
    "        })\n",
    "\n",
    "seasonal_impact_df = pd.DataFrame(seasonal_results)\n",
    "\n",
    "# Find stocks with strongest seasonal weather effects\n",
    "print(\"\\n--- Stocks Most Affected by Weather by Season ---\")\n",
    "for season in season_map.values():\n",
    "    season_df = seasonal_impact_df[seasonal_impact_df['Season'] == season]\n",
    "    if not season_df.empty:\n",
    "        top_stocks = season_df.sort_values('Weather_Impact', ascending=False).head(5)\n",
    "        print(f\"\\n{season}:\")\n",
    "        print(top_stocks)\n",
    "\n",
    "# Visualize the top stock-season combinations\n",
    "if len(seasonal_impact_df) > 0:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    top_overall = seasonal_impact_df.sort_values('Weather_Impact', ascending=False).head(15)\n",
    "    sns.barplot(x='Weather_Impact', y='Ticker', hue='Season', data=top_overall)\n",
    "    plt.title('Top 15 Stock-Season Combinations with Highest Weather Impact')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(weather_data_dir, 'top_stock_season_impact.png'))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08e38097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipping saving of large CSV files...\n",
      "\n",
      "Seasonal analysis complete! Results saved to the weather_data directory.\n",
      "\n",
      "=== SUMMARY OF FINDINGS ===\n",
      "1. Overall improvement from adding weather data: 0.0713\n",
      "2. Top weather features in importance ranking:\n",
      "   - wind_speed_10m_max\n",
      "   - wind_speed_10m_max_lag2\n",
      "   - wind_speed_10m_max_lag1\n",
      "   - temp_change\n",
      "   - temp_std_rolling7\n",
      "3. Seasons with strongest weather impact:\n",
      "   - Winter: 0.0661\n",
      "   - Spring: 0.0722\n",
      "   - Summer: 0.0785\n",
      "   - Fall: 0.0679\n",
      "4. Top 3 stocks most influenced by weather:\n",
      "   - AOS: 0.0196\n",
      "   - AES: 0.0180\n",
      "   - ANET: 0.0095\n",
      "\n",
      "Full analysis report has been saved to: weather_data\\weather_impact_report.md\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Save the final dataset with seasonal features - Modified to avoid CSV saving\n",
    "print(\"\\nSkipping saving of large CSV files...\")\n",
    "\n",
    "print(\"\\nSeasonal analysis complete! Results saved to the weather_data directory.\")\n",
    "\n",
    "# Display summary of findings\n",
    "print(\"\\n=== SUMMARY OF FINDINGS ===\")\n",
    "print(f\"1. Overall improvement from adding weather data: {np.mean(all_cv_scores) - np.mean(base_cv_scores):.4f}\")\n",
    "print(\"2. Top weather features in importance ranking:\")\n",
    "for feature in weather_in_top[:min(5, len(weather_in_top))]:\n",
    "    print(f\"   - {feature}\")\n",
    "print(\"3. Seasons with strongest weather impact:\")\n",
    "for season in range(1, 5):\n",
    "    if seasonal_cv_scores[season]:\n",
    "        avg_improvement = np.mean(seasonal_cv_scores[season])\n",
    "        season_name = season_map.get(season, f\"Season {season}\")\n",
    "        print(f\"   - {season_name}: {avg_improvement:.4f}\")\n",
    "\n",
    "# Calculate overall stock weather sensitivity\n",
    "if len(seasonal_impact_df) > 0:\n",
    "    ticker_impact = seasonal_impact_df\n",
    "    print(\"4. Top 3 stocks most influenced by weather:\")\n",
    "    top_stocks = seasonal_impact_df.groupby('Ticker')['Weather_Impact'].mean().sort_values(ascending=False).head(3)\n",
    "    for stock, impact in top_stocks.items():\n",
    "        print(f\"   - {stock}: {impact:.4f}\")\n",
    "\n",
    "# Create a comprehensive report with findings\n",
    "report = f\"\"\"\n",
    "# Weather Impact on Stock Price Prediction Analysis Report\n",
    "\n",
    "## Overview\n",
    "This analysis explored the impact of weather data on stock price prediction accuracy for S&P 500 stocks.\n",
    "The analysis incorporated seasonal patterns and weather anomalies to determine whether and when\n",
    "weather conditions influence stock price movements.\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. **Overall Impact**: Adding weather features {('improved' if np.mean(all_cv_scores) > np.mean(base_cv_scores) else 'did not improve')} prediction accuracy \n",
    "   by {abs(np.mean(all_cv_scores) - np.mean(base_cv_scores)):.4f} on average.\n",
    "\n",
    "2. **Most Important Weather Features**:\n",
    "   {', '.join(weather_in_top[:min(5, len(weather_in_top))])}\n",
    "\n",
    "3. **Seasonal Effects**:\n",
    "\"\"\"\n",
    "\n",
    "for season in range(1, 5):\n",
    "    if seasonal_cv_scores[season]:\n",
    "        avg_improvement = np.mean(seasonal_cv_scores[season])\n",
    "        season_name = season_map.get(season, f\"Season {season}\")\n",
    "        report += \"\"\"\n",
    "5. **Stock-Season Combinations with Strongest Weather Impact**:\n",
    "\"\"\"\n",
    "    top_combinations = seasonal_impact_df.sort_values('Weather_Impact', ascending=False).head(5)\n",
    "    for _, row in top_combinations.iterrows():\n",
    "        report += f\"   - {row['Ticker']} in {row['Season']}: {row['Weather_Impact']:.4f} accuracy improvement\\n\"\n",
    "\n",
    "# Save the report\n",
    "with open(os.path.join(weather_data_dir, 'weather_impact_report.md'), 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\nFull analysis report has been saved to:\", os.path.join(weather_data_dir, 'weather_impact_report.md'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f88ad421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Enhanced Trading Simulation ---\n",
      "Selected top tickers for simulation: ['IFF', 'K', 'KMX', 'LEN', 'LH']\n",
      "Simulation data shape: (18840, 100)\n",
      "\n",
      "Running base model trading simulation...\n",
      "\n",
      "Running enhanced simulation for Base Model...\n",
      "\n",
      "--- Base Model Trading Simulation Results ---\n",
      "Total Return: 4.1598 (415.98%)\n",
      "Annualized Return: 0.2782 (27.82%)\n",
      "Sharpe Ratio: 0.4653\n",
      "Max Drawdown: -0.4372 (-43.72%)\n",
      "Win Rate: 1.0000 (100.00%)\n",
      "Number of Trades: 63\n",
      "\n",
      "Running combined model trading simulation...\n",
      "\n",
      "Running enhanced simulation for Combined Model...\n",
      "\n",
      "--- Combined Model Trading Simulation Results ---\n",
      "Total Return: 234.8231 (23482.31%)\n",
      "Annualized Return: 15.7047 (1570.47%)\n",
      "Sharpe Ratio: 1.3630\n",
      "Max Drawdown: -0.3549 (-35.49%)\n",
      "Win Rate: 1.0000 (100.00%)\n",
      "Number of Trades: 1046\n",
      "\n",
      "--- Trading Performance Comparison ---\n",
      "              Metric Base Model Combined Model Improvement\n",
      "0       total_return    415.98%      23482.31%   23066.33%\n",
      "1  annualized_return     27.82%       1570.47%    1542.65%\n",
      "2       sharpe_ratio     0.4653       1.363036    0.897735\n",
      "3       max_drawdown    -43.72%        -35.49%       8.23%\n",
      "4           win_rate    100.00%        100.00%       0.00%\n",
      "5           n_trades       63.0         1046.0       983.0\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Enhanced trading simulation to estimate actual gains - Fixed\n",
    "print(\"\\n--- Running Enhanced Trading Simulation ---\")\n",
    "\n",
    "def enhanced_trading_simulation(model, X, ticker_data, feature_set_name, initial_investment=10000):\n",
    "    \"\"\"\n",
    "    Run a more realistic trading simulation with portfolio tracking\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : sklearn model\n",
    "        Trained prediction model\n",
    "    X : DataFrame\n",
    "        Feature data\n",
    "    ticker_data : DataFrame\n",
    "        Stock data with dates and prices\n",
    "    feature_set_name : str\n",
    "        Name of the feature set used\n",
    "    initial_investment : float\n",
    "        Initial investment amount\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    portfolio_df : DataFrame\n",
    "        DataFrame with portfolio performance\n",
    "    metrics : dict\n",
    "        Performance metrics\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import matplotlib.dates as mdates\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    \n",
    "    print(f\"\\nRunning enhanced simulation for {feature_set_name}...\")\n",
    "    \n",
    "    # Scale features\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Get predictions\n",
    "        y_pred = model.predict(X_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Create signals dataframe\n",
    "    signals_df = pd.DataFrame({\n",
    "        'Date': ticker_data['Date'],\n",
    "        'Ticker': ticker_data['Ticker'],\n",
    "        'Close': ticker_data['Close'],\n",
    "        'Predicted': y_pred,\n",
    "        'Confidence': y_pred_proba\n",
    "    })\n",
    "    \n",
    "    # Convert signals to Buy/Sell/Hold\n",
    "    # Use probability threshold to determine confidence level\n",
    "    signals_df['Signal'] = 'Hold'\n",
    "    signals_df.loc[signals_df['Confidence'] > 0.7, 'Signal'] = 'Buy'\n",
    "    signals_df.loc[signals_df['Confidence'] < 0.3, 'Signal'] = 'Sell'\n",
    "    \n",
    "    # Sort by date for chronological simulation\n",
    "    signals_df = signals_df.sort_values(['Date', 'Ticker'])\n",
    "    \n",
    "    # Group by ticker to simulate trading for each stock separately\n",
    "    portfolio_results = []\n",
    "    \n",
    "    for ticker in signals_df['Ticker'].unique():\n",
    "        ticker_signals = signals_df[signals_df['Ticker'] == ticker].copy()\n",
    "        if len(ticker_signals) < 30:  # Skip if not enough data points\n",
    "            continue\n",
    "            \n",
    "        # Initialize portfolio tracking\n",
    "        ticker_signals['Position'] = 0  # 0 = no position, 1 = long position\n",
    "        ticker_signals['Portfolio_Value'] = initial_investment\n",
    "        ticker_signals['Cash'] = initial_investment\n",
    "        ticker_signals['Shares'] = 0\n",
    "        ticker_signals['Trade'] = 'None'\n",
    "        ticker_signals['Trade_Price'] = np.nan\n",
    "        ticker_signals['Return'] = 0.0\n",
    "        \n",
    "        # Simulation with slippage and transaction costs\n",
    "        transaction_cost_pct = 0.001  # 0.1% per trade\n",
    "        slippage_pct = 0.001  # 0.1% slippage\n",
    "        \n",
    "        for i in range(1, len(ticker_signals)):\n",
    "            prev = ticker_signals.iloc[i-1]\n",
    "            curr = ticker_signals.iloc[i]\n",
    "            \n",
    "            # Default: carry forward previous position and values\n",
    "            ticker_signals.loc[ticker_signals.index[i], 'Position'] = prev['Position']\n",
    "            ticker_signals.loc[ticker_signals.index[i], 'Cash'] = prev['Cash']\n",
    "            ticker_signals.loc[ticker_signals.index[i], 'Shares'] = prev['Shares']\n",
    "            \n",
    "            # Trading logic with signals\n",
    "            if prev['Signal'] == 'Buy' and prev['Position'] == 0:\n",
    "                # Buy with slippage\n",
    "                buy_price = prev['Close'] * (1 + slippage_pct)\n",
    "                transaction_cost = prev['Cash'] * transaction_cost_pct\n",
    "                available_cash = prev['Cash'] - transaction_cost\n",
    "                shares_to_buy = available_cash / buy_price\n",
    "                \n",
    "                # Update position\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Position'] = 1\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Cash'] = 0\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Shares'] = shares_to_buy\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Trade'] = 'Buy'\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Trade_Price'] = buy_price\n",
    "                \n",
    "            elif prev['Signal'] == 'Sell' and prev['Position'] == 1:\n",
    "                # Sell with slippage\n",
    "                sell_price = prev['Close'] * (1 - slippage_pct)\n",
    "                shares_value = prev['Shares'] * sell_price\n",
    "                transaction_cost = shares_value * transaction_cost_pct\n",
    "                cash_after_sale = shares_value - transaction_cost\n",
    "                \n",
    "                # Update position\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Position'] = 0\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Cash'] = cash_after_sale\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Shares'] = 0\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Trade'] = 'Sell'\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Trade_Price'] = sell_price\n",
    "            \n",
    "            # Calculate current portfolio value\n",
    "            if ticker_signals.loc[ticker_signals.index[i], 'Position'] == 1:\n",
    "                # Long position: value is in shares\n",
    "                shares_value = ticker_signals.loc[ticker_signals.index[i], 'Shares'] * curr['Close']\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Portfolio_Value'] = shares_value\n",
    "            else:\n",
    "                # No position: value is cash\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Portfolio_Value'] = ticker_signals.loc[ticker_signals.index[i], 'Cash']\n",
    "            \n",
    "            # Calculate daily return\n",
    "            ticker_signals.loc[ticker_signals.index[i], 'Return'] = (\n",
    "                ticker_signals.loc[ticker_signals.index[i], 'Portfolio_Value'] / \n",
    "                ticker_signals.loc[ticker_signals.index[i-1], 'Portfolio_Value'] - 1\n",
    "            )\n",
    "        \n",
    "        # Add to combined results\n",
    "        portfolio_results.append(ticker_signals)\n",
    "    \n",
    "    # Combine all portfolio results\n",
    "    if portfolio_results:\n",
    "        try:\n",
    "            portfolio_df = pd.concat(portfolio_results, ignore_index=True)\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            total_return = (portfolio_df.groupby('Ticker')['Portfolio_Value'].last() / initial_investment - 1).mean()\n",
    "            \n",
    "            # Calculate Sharpe ratio with error handling\n",
    "            try:\n",
    "                sharpe_ratio = portfolio_df.groupby('Ticker')['Return'].mean() / portfolio_df.groupby('Ticker')['Return'].std() * np.sqrt(252)  # Annualized\n",
    "                mean_sharpe = sharpe_ratio.mean()\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating Sharpe ratio: {e}\")\n",
    "                mean_sharpe = float('nan')\n",
    "            \n",
    "            # Calculate drawdowns\n",
    "            try:\n",
    "                for ticker in portfolio_df['Ticker'].unique():\n",
    "                    ticker_mask = portfolio_df['Ticker'] == ticker\n",
    "                    portfolio_df.loc[ticker_mask, 'Cum_Return'] = (1 + portfolio_df.loc[ticker_mask, 'Return']).cumprod()\n",
    "                    portfolio_df.loc[ticker_mask, 'Peak'] = portfolio_df.loc[ticker_mask, 'Cum_Return'].cummax()\n",
    "                    portfolio_df.loc[ticker_mask, 'Drawdown'] = (portfolio_df.loc[ticker_mask, 'Cum_Return'] / portfolio_df.loc[ticker_mask, 'Peak']) - 1\n",
    "                \n",
    "                max_drawdown = portfolio_df.groupby('Ticker')['Drawdown'].min().mean()\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating drawdowns: {e}\")\n",
    "                max_drawdown = float('nan')\n",
    "            \n",
    "            # Calculate win rate - THIS IS THE FIXED PART\n",
    "            try:\n",
    "                # Filter sell trades\n",
    "                sell_trades = portfolio_df[portfolio_df['Trade'] == 'Sell']\n",
    "                # Calculate previous cash values (shifted)\n",
    "                previous_cash = portfolio_df['Cash'].shift(1)\n",
    "                # Filter profitable sells (portfolio value > previous cash)\n",
    "                profitable_sells = portfolio_df[(portfolio_df['Trade'] == 'Sell') & \n",
    "                                               (portfolio_df['Portfolio_Value'] > previous_cash)]\n",
    "                \n",
    "                # Calculate win rate\n",
    "                win_rate = len(profitable_sells) / max(1, len(sell_trades))\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating win rate: {e}\")\n",
    "                win_rate = float('nan')\n",
    "            \n",
    "            # Count trades\n",
    "            n_trades = len(portfolio_df[portfolio_df['Trade'] != 'None'])\n",
    "            \n",
    "            metrics = {\n",
    "                'total_return': total_return,\n",
    "                'annualized_return': total_return * (252 / max(1, len(portfolio_df['Date'].unique()))),\n",
    "                'sharpe_ratio': mean_sharpe,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'win_rate': win_rate,\n",
    "                'n_trades': n_trades\n",
    "            }\n",
    "            \n",
    "            # Print performance metrics\n",
    "            print(f\"\\n--- {feature_set_name} Trading Simulation Results ---\")\n",
    "            print(f\"Total Return: {metrics['total_return']:.4f} ({metrics['total_return'] * 100:.2f}%)\")\n",
    "            print(f\"Annualized Return: {metrics['annualized_return']:.4f} ({metrics['annualized_return'] * 100:.2f}%)\")\n",
    "            \n",
    "            if not np.isnan(metrics['sharpe_ratio']):\n",
    "                print(f\"Sharpe Ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "            else:\n",
    "                print(\"Sharpe Ratio: Not available\")\n",
    "                \n",
    "            print(f\"Max Drawdown: {metrics['max_drawdown']:.4f} ({metrics['max_drawdown'] * 100:.2f}%)\")\n",
    "            print(f\"Win Rate: {metrics['win_rate']:.4f} ({metrics['win_rate'] * 100:.2f}%)\")\n",
    "            print(f\"Number of Trades: {metrics['n_trades']}\")\n",
    "            \n",
    "            # Plot portfolio performance for top performers\n",
    "            try:\n",
    "                top_performers = portfolio_df.groupby('Ticker')['Portfolio_Value'].last() / initial_investment\n",
    "                top_performers = top_performers.sort_values(ascending=False).head(5)\n",
    "                \n",
    "                for ticker in top_performers.index:\n",
    "                    ticker_data = portfolio_df[portfolio_df['Ticker'] == ticker].copy()\n",
    "                    \n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    \n",
    "                    # Portfolio value over time\n",
    "                    plt.subplot(2, 1, 1)\n",
    "                    plt.plot(ticker_data['Date'], ticker_data['Portfolio_Value'], label='Portfolio Value')\n",
    "                    \n",
    "                    # Mark buy/sell points\n",
    "                    buys = ticker_data[ticker_data['Trade'] == 'Buy']\n",
    "                    sells = ticker_data[ticker_data['Trade'] == 'Sell']\n",
    "                    \n",
    "                    plt.scatter(buys['Date'], buys['Portfolio_Value'], marker='^', color='green', s=100, label='Buy')\n",
    "                    plt.scatter(sells['Date'], sells['Portfolio_Value'], marker='v', color='red', s=100, label='Sell')\n",
    "                    \n",
    "                    plt.title(f'{ticker} Portfolio Performance - {feature_set_name}')\n",
    "                    plt.ylabel('Portfolio Value ($)')\n",
    "                    plt.legend()\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Drawdown chart\n",
    "                    plt.subplot(2, 1, 2)\n",
    "                    plt.fill_between(ticker_data['Date'], ticker_data['Drawdown'] * 100, 0, color='red', alpha=0.3)\n",
    "                    plt.plot(ticker_data['Date'], ticker_data['Drawdown'] * 100, color='red', label='Drawdown %')\n",
    "                    \n",
    "                    plt.title(f'{ticker} Drawdown')\n",
    "                    plt.ylabel('Drawdown (%)')\n",
    "                    plt.xlabel('Date')\n",
    "                    plt.legend()\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(weather_data_dir, f'{ticker}_{feature_set_name.replace(\" \", \"_\").lower()}_performance.png'))\n",
    "                    plt.close()\n",
    "                \n",
    "                # Compare portfolio growth across all tickers\n",
    "                plt.figure(figsize=(14, 8))\n",
    "                for ticker in portfolio_df['Ticker'].unique():\n",
    "                    ticker_data = portfolio_df[portfolio_df['Ticker'] == ticker]\n",
    "                    if len(ticker_data) > 0:\n",
    "                        plt.plot(ticker_data['Date'], ticker_data['Portfolio_Value'], label=ticker, alpha=0.7)\n",
    "                \n",
    "                plt.axhline(y=initial_investment, color='k', linestyle='-', alpha=0.3)\n",
    "                plt.title(f'Portfolio Growth Comparison - {feature_set_name}')\n",
    "                plt.ylabel('Portfolio Value ($)')\n",
    "                plt.xlabel('Date')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(weather_data_dir, f'portfolio_comparison_{feature_set_name.replace(\" \", \"_\").lower()}.png'))\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error in plotting: {e}\")\n",
    "            \n",
    "            return portfolio_df, metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error in performance calculation: {e}\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"No valid trading data for simulation.\")\n",
    "        return None, None\n",
    "\n",
    "# Run simulations with both models for comparison\n",
    "try:\n",
    "    # Select specific tickers for more detailed simulation to avoid excessive computation\n",
    "    top_tickers = combined_df['Ticker'].value_counts().head(5).index.tolist()\n",
    "    print(f\"Selected top tickers for simulation: {top_tickers}\")\n",
    "    simulation_data = combined_df[combined_df['Ticker'].isin(top_tickers)].copy()\n",
    "    \n",
    "    if len(simulation_data) < 100:\n",
    "        print(f\"Warning: Only {len(simulation_data)} data points for selected tickers. Selecting more tickers...\")\n",
    "        top_tickers = combined_df['Ticker'].value_counts().head(10).index.tolist()\n",
    "        simulation_data = combined_df[combined_df['Ticker'].isin(top_tickers)].copy()\n",
    "    \n",
    "    print(f\"Simulation data shape: {simulation_data.shape}\")\n",
    "    \n",
    "    # Base model simulation (stock data only)\n",
    "    print(\"\\nRunning base model trading simulation...\")\n",
    "    base_X = simulation_data[base_features]\n",
    "    base_portfolio, base_metrics = enhanced_trading_simulation(\n",
    "        base_model, base_X, simulation_data, \"Base Model\", initial_investment=10000\n",
    "    )\n",
    "    \n",
    "    # Combined model simulation (stock + weather)\n",
    "    print(\"\\nRunning combined model trading simulation...\")\n",
    "    all_X = simulation_data[all_features]\n",
    "    all_portfolio, all_metrics = enhanced_trading_simulation(\n",
    "        all_model, all_X, simulation_data, \"Combined Model\", initial_investment=10000\n",
    "    )\n",
    "    \n",
    "    # Compare trading performance between models\n",
    "    if base_metrics and all_metrics:\n",
    "        try:\n",
    "            # Create comparison dataframe for key metrics\n",
    "            metrics_comparison = pd.DataFrame({\n",
    "                'Metric': list(base_metrics.keys()),\n",
    "                'Base Model': list(base_metrics.values()),\n",
    "                'Combined Model': list(all_metrics.values()),\n",
    "                'Improvement': [all_metrics[key] - base_metrics[key] for key in base_metrics.keys()]\n",
    "            })\n",
    "            \n",
    "            # Convert to string representations for display\n",
    "            metrics_comparison_display = metrics_comparison.copy()\n",
    "            \n",
    "            # Format as percentages where appropriate\n",
    "            percent_metrics = ['total_return', 'annualized_return', 'max_drawdown', 'win_rate']\n",
    "            for metric in percent_metrics:\n",
    "                try:\n",
    "                    idx = metrics_comparison_display.index[metrics_comparison_display['Metric'] == metric][0]\n",
    "                    metrics_comparison_display.loc[idx, 'Base Model'] = f\"{base_metrics[metric] * 100:.2f}%\"\n",
    "                    metrics_comparison_display.loc[idx, 'Combined Model'] = f\"{all_metrics[metric] * 100:.2f}%\"\n",
    "                    metrics_comparison_display.loc[idx, 'Improvement'] = f\"{(all_metrics[metric] - base_metrics[metric]) * 100:.2f}%\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error formatting {metric}: {e}\")\n",
    "            \n",
    "            print(\"\\n--- Trading Performance Comparison ---\")\n",
    "            print(metrics_comparison_display)\n",
    "            \n",
    "            # Visualize performance comparison\n",
    "            try:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                \n",
    "                # Create bar chart for key numerical metrics\n",
    "                numerical_metrics = ['sharpe_ratio', 'n_trades']\n",
    "                metrics_df = pd.DataFrame({\n",
    "                    'Metric': numerical_metrics,\n",
    "                    'Base Model': [base_metrics[m] for m in numerical_metrics],\n",
    "                    'Combined Model': [all_metrics[m] for m in numerical_metrics]\n",
    "                })\n",
    "                \n",
    "                # Reshape for plotting\n",
    "                plot_df = pd.melt(metrics_df, id_vars=['Metric'], var_name='Model', value_name='Value')\n",
    "                \n",
    "                # Plot\n",
    "                import seaborn as sns\n",
    "                sns.barplot(x='Metric', y='Value', hue='Model', data=plot_df)\n",
    "                plt.title('Trading Performance Metrics Comparison')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.savefig(os.path.join(weather_data_dir, 'trading_metrics_comparison.png'))\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating metrics comparison plot: {e}\")\n",
    "            \n",
    "            # Plot cumulative returns comparison - average across all tickers for each model\n",
    "            if base_portfolio is not None and all_portfolio is not None:\n",
    "                try:\n",
    "                    # Calculate mean portfolio value by date for each model\n",
    "                    base_daily = base_portfolio.groupby(['Date'])['Portfolio_Value'].mean().reset_index()\n",
    "                    base_daily['Relative_Value'] = base_daily['Portfolio_Value'] / 10000\n",
    "                    \n",
    "                    all_daily = all_portfolio.groupby(['Date'])['Portfolio_Value'].mean().reset_index()\n",
    "                    all_daily['Relative_Value'] = all_daily['Portfolio_Value'] / 10000\n",
    "                    \n",
    "                    # Plot comparison\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    plt.plot(base_daily['Date'], base_daily['Relative_Value'], label='Base Model', color='blue')\n",
    "                    plt.plot(all_daily['Date'], all_daily['Relative_Value'], label='Combined Model', color='green')\n",
    "                    \n",
    "                    plt.axhline(y=1, color='k', linestyle='-', alpha=0.3)\n",
    "                    plt.title('Average Cumulative Return Comparison')\n",
    "                    plt.ylabel('Portfolio Value (Relative to Initial Investment)')\n",
    "                    plt.xlabel('Date')\n",
    "                    plt.legend()\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(weather_data_dir, 'cumulative_return_comparison.png'))\n",
    "                    plt.close()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating cumulative returns plot: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in metrics comparison: {e}\")\n",
    "    else:\n",
    "        print(\"Could not compare metrics: one or both simulations failed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in simulation setup: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fdbab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simple Moving Average (SMA) Trading Strategy Benchmark ---\n",
      "Analyzing SMA strategy for tickers: ['AOS', 'AES', 'ANET', 'ALL', 'APH']\n",
      "\n",
      "Implementing SMA trading strategy benchmark...\n",
      "Using SMA parameters: short_window=20, long_window=50\n",
      "\n",
      "Running SMA strategy for AOS...\n",
      "\n",
      "AOS SMA Strategy Performance Summary:\n",
      "SMA Strategy Return: 0.5499 (54.99%)\n",
      "Buy and Hold Return: 8.2428 (824.28%)\n",
      "SMA Sharpe Ratio: 0.1843\n",
      "Total Trades: 86\n",
      "\n",
      "Running SMA strategy for AES...\n",
      "\n",
      "AES SMA Strategy Performance Summary:\n",
      "SMA Strategy Return: 0.0013 (0.13%)\n",
      "Buy and Hold Return: -0.0490 (-4.90%)\n",
      "SMA Sharpe Ratio: 0.0004\n",
      "Total Trades: 94\n",
      "\n",
      "Running SMA strategy for ANET...\n",
      "\n",
      "ANET SMA Strategy Performance Summary:\n",
      "SMA Strategy Return: 3.4209 (342.09%)\n",
      "Buy and Hold Return: 31.8175 (3181.75%)\n",
      "SMA Sharpe Ratio: 0.9677\n",
      "Total Trades: 55\n",
      "\n",
      "Running SMA strategy for ALL...\n",
      "\n",
      "ALL SMA Strategy Performance Summary:\n",
      "SMA Strategy Return: 1.5533 (155.33%)\n",
      "Buy and Hold Return: 5.3650 (536.50%)\n",
      "SMA Sharpe Ratio: 0.6306\n",
      "Total Trades: 79\n",
      "\n",
      "Running SMA strategy for APH...\n",
      "\n",
      "APH SMA Strategy Performance Summary:\n",
      "SMA Strategy Return: 2.9754 (297.54%)\n",
      "Buy and Hold Return: 11.2908 (1129.08%)\n",
      "SMA Sharpe Ratio: 1.1524\n",
      "Total Trades: 81\n",
      "\n",
      "=== Overall SMA Strategy Results ===\n",
      "Average SMA Strategy Return: 1.7002 (170.02%)\n",
      "Average Buy & Hold Return: 11.3334 (1133.34%)\n",
      "Average Outperformance: -9.6332 (-963.32%)\n",
      "Average SMA Sharpe Ratio: 0.5871\n",
      "Average Number of Trades: 79.0\n",
      "Warning: strategy_summary is not defined. Skipping strategy comparison.\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Add Simple Moving Average (SMA) Trading Strategy as Benchmark\n",
    "print(\"\\n--- Simple Moving Average (SMA) Trading Strategy Benchmark ---\")\n",
    "\n",
    "def sma_trading_strategy(combined_df, weather_sensitive_stocks):\n",
    "    \"\"\"\n",
    "    Implement a Simple Moving Average (SMA) trading strategy as a benchmark\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    combined_df : DataFrame\n",
    "        Combined stock and weather data\n",
    "    weather_sensitive_stocks : list\n",
    "        List of tickers to analyze (same as weather-sensitive strategy)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    strategy_df : DataFrame\n",
    "        DataFrame with strategy performance\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    \n",
    "    print(\"\\nImplementing SMA trading strategy benchmark...\")\n",
    "    \n",
    "    # Parameters for SMA strategy\n",
    "    short_window = 20  # Short moving average window (days)\n",
    "    long_window = 50   # Long moving average window (days)\n",
    "    \n",
    "    print(f\"Using SMA parameters: short_window={short_window}, long_window={long_window}\")\n",
    "    \n",
    "    # Filter data to include only the stocks we're analyzing\n",
    "    strategy_data = combined_df[combined_df['Ticker'].isin(weather_sensitive_stocks)].copy()\n",
    "    \n",
    "    # Strategy results and performance summary\n",
    "    strategy_results = []\n",
    "    performance_summary = []\n",
    "    \n",
    "    for ticker in weather_sensitive_stocks:\n",
    "        print(f\"\\nRunning SMA strategy for {ticker}...\")\n",
    "        ticker_data = strategy_data[strategy_data['Ticker'] == ticker].copy()\n",
    "        \n",
    "        if len(ticker_data) < long_window + 10:\n",
    "            print(f\"Not enough data for {ticker}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Sort by date for calculations\n",
    "        ticker_data = ticker_data.sort_values('Date')\n",
    "        \n",
    "        # Calculate moving averages\n",
    "        ticker_data['SMA_Short'] = ticker_data['Close'].rolling(window=short_window, min_periods=1).mean()\n",
    "        ticker_data['SMA_Long'] = ticker_data['Close'].rolling(window=long_window, min_periods=1).mean()\n",
    "        \n",
    "        # Generate signals: 1 = Buy, 0 = Sell\n",
    "        ticker_data['Signal'] = 0\n",
    "        ticker_data.loc[ticker_data['SMA_Short'] > ticker_data['SMA_Long'], 'Signal'] = 1\n",
    "        \n",
    "        # Create a new column for signal changes\n",
    "        ticker_data['Position'] = ticker_data['Signal'].diff()\n",
    "        \n",
    "        # Initialize trading simulation\n",
    "        initial_investment = 10000\n",
    "        ticker_data['SMA_Cash'] = initial_investment\n",
    "        ticker_data['SMA_Shares'] = 0\n",
    "        ticker_data['SMA_Portfolio'] = initial_investment\n",
    "        ticker_data['SMA_Return'] = 0.0\n",
    "        ticker_data['SMA_Trade'] = 'None'\n",
    "        \n",
    "        # Parameters for trading costs\n",
    "        transaction_cost_pct = 0.001  # 0.1% per trade\n",
    "        slippage_pct = 0.001  # 0.1% slippage\n",
    "        \n",
    "        # Backtest strategy\n",
    "        position = 0\n",
    "        for i in range(1, len(ticker_data)):\n",
    "            prev_row = ticker_data.iloc[i-1]\n",
    "            curr_row = ticker_data.iloc[i]\n",
    "            \n",
    "            # Default: carry forward previous values\n",
    "            ticker_data.loc[ticker_data.index[i], 'SMA_Cash'] = prev_row['SMA_Cash']\n",
    "            ticker_data.loc[ticker_data.index[i], 'SMA_Shares'] = prev_row['SMA_Shares']\n",
    "            \n",
    "            # Check for signal changes\n",
    "            if prev_row['Position'] == 1:  # Buy signal\n",
    "                # Buy with slippage\n",
    "                buy_price = prev_row['Close'] * (1 + slippage_pct)\n",
    "                transaction_cost = prev_row['SMA_Cash'] * transaction_cost_pct\n",
    "                shares_to_buy = (prev_row['SMA_Cash'] - transaction_cost) / buy_price if buy_price > 0 else 0\n",
    "                \n",
    "                # Update position\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Cash'] = 0\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Shares'] = shares_to_buy\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Trade'] = 'Buy'\n",
    "                \n",
    "                position = 1\n",
    "            \n",
    "            elif prev_row['Position'] == -1:  # Sell signal\n",
    "                # Sell with slippage\n",
    "                sell_price = prev_row['Close'] * (1 - slippage_pct)\n",
    "                shares_value = prev_row['SMA_Shares'] * sell_price\n",
    "                transaction_cost = shares_value * transaction_cost_pct\n",
    "                \n",
    "                # Update position\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Cash'] = shares_value - transaction_cost\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Shares'] = 0\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Trade'] = 'Sell'\n",
    "                \n",
    "                position = 0\n",
    "            \n",
    "            # Calculate current portfolio value\n",
    "            if position == 1:\n",
    "                shares_value = ticker_data.loc[ticker_data.index[i], 'SMA_Shares'] * curr_row['Close']\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Portfolio'] = shares_value\n",
    "            else:\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Portfolio'] = ticker_data.loc[ticker_data.index[i], 'SMA_Cash']\n",
    "            \n",
    "            # Calculate daily return\n",
    "            if prev_row['SMA_Portfolio'] > 0:\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Return'] = (\n",
    "                    ticker_data.loc[ticker_data.index[i], 'SMA_Portfolio'] / \n",
    "                    prev_row['SMA_Portfolio'] - 1\n",
    "                )\n",
    "            else:\n",
    "                ticker_data.loc[ticker_data.index[i], 'SMA_Return'] = 0\n",
    "        \n",
    "        # Calculate cumulative returns\n",
    "        ticker_data['SMA_Cum_Return'] = (1 + ticker_data['SMA_Return']).cumprod()\n",
    "        \n",
    "        # Calculate buy-and-hold returns for comparison\n",
    "        ticker_data['BuyHold_Return'] = ticker_data['Close'] / ticker_data['Close'].iloc[0]\n",
    "        \n",
    "        # Calculate final returns\n",
    "        final_sma_return = ticker_data['SMA_Portfolio'].iloc[-1] / initial_investment - 1\n",
    "        final_buy_hold = ticker_data['BuyHold_Return'].iloc[-1] - 1\n",
    "        \n",
    "        # Calculate risk metrics\n",
    "        sma_vol = ticker_data['SMA_Return'].std() * np.sqrt(252)  # Annualized\n",
    "        sma_sharpe = (final_sma_return / len(ticker_data) * 252) / max(sma_vol, 0.0001)  # Avoid division by zero\n",
    "        \n",
    "        # Count trades\n",
    "        sma_trades = len(ticker_data[ticker_data['SMA_Trade'] != 'None'])\n",
    "        \n",
    "        # Add to results\n",
    "        strategy_results.append(ticker_data)\n",
    "        \n",
    "        # Display performance summary\n",
    "        print(f\"\\n{ticker} SMA Strategy Performance Summary:\")\n",
    "        print(f\"SMA Strategy Return: {final_sma_return:.4f} ({final_sma_return * 100:.2f}%)\")\n",
    "        print(f\"Buy and Hold Return: {final_buy_hold:.4f} ({final_buy_hold * 100:.2f}%)\")\n",
    "        print(f\"SMA Sharpe Ratio: {sma_sharpe:.4f}\")\n",
    "        print(f\"Total Trades: {sma_trades}\")\n",
    "        \n",
    "        # Create visualization\n",
    "        try:\n",
    "            plt.figure(figsize=(14, 10))\n",
    "            \n",
    "            # Price and moving averages\n",
    "            plt.subplot(3, 1, 1)\n",
    "            plt.plot(ticker_data['Date'], ticker_data['Close'], label='Close Price', alpha=0.6)\n",
    "            plt.plot(ticker_data['Date'], ticker_data['SMA_Short'], label=f'SMA ({short_window})', color='orange')\n",
    "            plt.plot(ticker_data['Date'], ticker_data['SMA_Long'], label=f'SMA ({long_window})', color='blue')\n",
    "            \n",
    "            # Mark buy/sell points\n",
    "            buys = ticker_data[ticker_data['SMA_Trade'] == 'Buy']\n",
    "            sells = ticker_data[ticker_data['SMA_Trade'] == 'Sell']\n",
    "            \n",
    "            if len(buys) > 0:\n",
    "                plt.scatter(buys['Date'], buys['Close'], marker='^', color='green', s=100, label='Buy Signal')\n",
    "            if len(sells) > 0:\n",
    "                plt.scatter(sells['Date'], sells['Close'], marker='v', color='red', s=100, label='Sell Signal')\n",
    "            \n",
    "            plt.title(f'{ticker} Price and Moving Averages')\n",
    "            plt.ylabel('Price ($)')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Portfolio value\n",
    "            plt.subplot(3, 1, 2)\n",
    "            plt.plot(ticker_data['Date'], ticker_data['SMA_Portfolio'], label='SMA Strategy', color='blue')\n",
    "            plt.axhline(y=initial_investment, color='k', linestyle='--', alpha=0.3, label='Initial Investment')\n",
    "            \n",
    "            plt.title(f'{ticker} SMA Strategy Portfolio Value')\n",
    "            plt.ylabel('Portfolio Value ($)')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Cumulative returns comparison\n",
    "            plt.subplot(3, 1, 3)\n",
    "            plt.plot(ticker_data['Date'], ticker_data['SMA_Cum_Return'], label='SMA Strategy', color='blue')\n",
    "            plt.plot(ticker_data['Date'], ticker_data['BuyHold_Return'], label='Buy and Hold', color='green', linestyle=':')\n",
    "            \n",
    "            plt.title(f'{ticker} Cumulative Returns Comparison')\n",
    "            plt.ylabel('Cumulative Return (Starting = 1)')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(weather_data_dir, f'{ticker}_sma_strategy.png'))\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {e}\")\n",
    "        \n",
    "        # Add to performance summary\n",
    "        performance_summary.append({\n",
    "            'Ticker': ticker,\n",
    "            'SMA_Return': final_sma_return,\n",
    "            'BuyHold_Return': final_buy_hold,\n",
    "            'Outperformance': final_sma_return - final_buy_hold,\n",
    "            'SMA_Sharpe': sma_sharpe,\n",
    "            'SMA_Trades': sma_trades\n",
    "        })\n",
    "    \n",
    "    # Combine all results\n",
    "    if strategy_results and len(strategy_results) > 0:\n",
    "        try:\n",
    "            all_results = pd.concat(strategy_results, ignore_index=True)\n",
    "            \n",
    "            # Create summary dataframe\n",
    "            if performance_summary:\n",
    "                summary_df = pd.DataFrame(performance_summary)\n",
    "                \n",
    "                # Print overall results\n",
    "                print(\"\\n=== Overall SMA Strategy Results ===\")\n",
    "                print(f\"Average SMA Strategy Return: {summary_df['SMA_Return'].mean():.4f} ({summary_df['SMA_Return'].mean() * 100:.2f}%)\")\n",
    "                print(f\"Average Buy & Hold Return: {summary_df['BuyHold_Return'].mean():.4f} ({summary_df['BuyHold_Return'].mean() * 100:.2f}%)\")\n",
    "                print(f\"Average Outperformance: {summary_df['Outperformance'].mean():.4f} ({summary_df['Outperformance'].mean() * 100:.2f}%)\")\n",
    "                print(f\"Average SMA Sharpe Ratio: {summary_df['SMA_Sharpe'].mean():.4f}\")\n",
    "                print(f\"Average Number of Trades: {summary_df['SMA_Trades'].mean():.1f}\")\n",
    "                \n",
    "                # Plot summary across tickers\n",
    "                try:\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    \n",
    "                    x = np.arange(len(summary_df))\n",
    "                    width = 0.35\n",
    "                    \n",
    "                    plt.bar(x - width/2, summary_df['SMA_Return'] * 100, width, label='SMA Strategy')\n",
    "                    plt.bar(x + width/2, summary_df['BuyHold_Return'] * 100, width, label='Buy & Hold')\n",
    "                    \n",
    "                    plt.xlabel('Ticker')\n",
    "                    plt.ylabel('Return (%)')\n",
    "                    plt.title('SMA Strategy vs Buy & Hold Returns by Ticker')\n",
    "                    plt.xticks(x, summary_df['Ticker'])\n",
    "                    plt.legend()\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(weather_data_dir, 'sma_strategy_comparison.png'))\n",
    "                    plt.close()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating summary plots: {e}\")\n",
    "                \n",
    "                return all_results, summary_df\n",
    "            else:\n",
    "                return all_results, None\n",
    "        except Exception as e:\n",
    "            print(f\"Error combining results: {e}\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"No strategy results collected.\")\n",
    "        return None, None\n",
    "\n",
    "# Run the SMA trading strategy\n",
    "try:\n",
    "    # Use the same stocks as in the weather-sensitive strategy\n",
    "    if 'seasonal_impact_df' in globals() and len(seasonal_impact_df) > 0:\n",
    "        weather_sensitive_stocks = seasonal_impact_df.groupby('Ticker')['Weather_Impact'].mean()\n",
    "        weather_sensitive_stocks = weather_sensitive_stocks.sort_values(ascending=False).head(5).index.tolist()\n",
    "    else:\n",
    "        # Fallback: use top 5 stocks by data volume\n",
    "        weather_sensitive_stocks = combined_df['Ticker'].value_counts().head(5).index.tolist()\n",
    "    \n",
    "    print(f\"Analyzing SMA strategy for tickers: {weather_sensitive_stocks}\")\n",
    "    \n",
    "    # Run SMA strategy\n",
    "    sma_results, sma_summary = sma_trading_strategy(combined_df, weather_sensitive_stocks)\n",
    "except Exception as e:\n",
    "    print(f\"Error running SMA strategy: {e}\")\n",
    "    sma_results, sma_summary = None, None\n",
    "\n",
    "# FIXED COMPARISON CODE: Check if both summaries exist before comparing\n",
    "# Define strategy_summary if it doesn't exist (from fixed_summary if available)\n",
    "if 'strategy_summary' not in globals() and 'fixed_summary' in globals():\n",
    "    strategy_summary = fixed_summary\n",
    "    print(\"Using fixed_summary as strategy_summary for comparison\")\n",
    "elif 'strategy_summary' not in globals():\n",
    "    print(\"Warning: strategy_summary is not defined. Skipping strategy comparison.\")\n",
    "    strategy_summary = None\n",
    "\n",
    "# Compare SMA strategy with weather-sensitive and base strategies\n",
    "if (sma_summary is not None and strategy_summary is not None and \n",
    "    len(sma_summary) > 0 and len(strategy_summary) > 0):\n",
    "    \n",
    "    try:\n",
    "        print(\"\\n--- Comparing All Strategies ---\")\n",
    "        \n",
    "        \n",
    "        # Merge summaries\n",
    "        comparison_data = []\n",
    "        \n",
    "        for ticker in weather_sensitive_stocks:\n",
    "            sma_data = sma_summary[sma_summary['Ticker'] == ticker]\n",
    "            weather_data = strategy_summary[strategy_summary['Ticker'] == ticker]\n",
    "            \n",
    "            if len(sma_data) > 0 and len(weather_data) > 0:\n",
    "                comparison_data.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Weather_Return': weather_data['Weather_Return'].values[0],\n",
    "                    'Basic_Return': weather_data['Basic_Return'].values[0],\n",
    "                    'SMA_Return': sma_data['SMA_Return'].values[0],\n",
    "                    'BuyHold_Return': sma_data['BuyHold_Return'].values[0],\n",
    "                    'Weather_Sharpe': weather_data['Weather_Sharpe'].values[0],\n",
    "                    'Basic_Sharpe': weather_data['Basic_Sharpe'].values[0],\n",
    "                    'SMA_Sharpe': sma_data['SMA_Sharpe'].values[0]\n",
    "                })\n",
    "        \n",
    "        if comparison_data:\n",
    "            # Create comparison dataframe\n",
    "            comparison_df = pd.DataFrame(comparison_data)\n",
    "            \n",
    "            # Print comparison summary\n",
    "            print(\"\\n=== Strategy Comparison by Average Returns ===\")\n",
    "            print(f\"Weather-Sensitive Strategy: {comparison_df['Weather_Return'].mean():.4f} ({comparison_df['Weather_Return'].mean() * 100:.2f}%)\")\n",
    "            print(f\"Basic Strategy: {comparison_df['Basic_Return'].mean():.4f} ({comparison_df['Basic_Return'].mean() * 100:.2f}%)\")\n",
    "            print(f\"SMA Strategy: {comparison_df['SMA_Return'].mean():.4f} ({comparison_df['SMA_Return'].mean() * 100:.2f}%)\")\n",
    "            print(f\"Buy and Hold: {comparison_df['BuyHold_Return'].mean():.4f} ({comparison_df['BuyHold_Return'].mean() * 100:.2f}%)\")\n",
    "            \n",
    "            print(\"\\n=== Strategy Comparison by Average Sharpe Ratio ===\")\n",
    "            print(f\"Weather-Sensitive Strategy: {comparison_df['Weather_Sharpe'].mean():.4f}\")\n",
    "            print(f\"Basic Strategy: {comparison_df['Basic_Sharpe'].mean():.4f}\")\n",
    "            print(f\"SMA Strategy: {comparison_df['SMA_Sharpe'].mean():.4f}\")\n",
    "            \n",
    "            # Create comprehensive comparison chart\n",
    "            try:\n",
    "                plt.figure(figsize=(14, 10))\n",
    "                \n",
    "                # Return comparison\n",
    "                plt.subplot(2, 1, 1)\n",
    "                x = np.arange(len(comparison_df))\n",
    "                width = 0.2\n",
    "                \n",
    "                plt.bar(x - width*1.5, comparison_df['Weather_Return'] * 100, width, label='Weather Strategy')\n",
    "                plt.bar(x - width/2, comparison_df['Basic_Return'] * 100, width, label='Basic Strategy')\n",
    "                plt.bar(x + width/2, comparison_df['SMA_Return'] * 100, width, label='SMA Strategy')\n",
    "                plt.bar(x + width*1.5, comparison_df['BuyHold_Return'] * 100, width, label='Buy & Hold')\n",
    "                \n",
    "                plt.xlabel('Ticker')\n",
    "                plt.ylabel('Return (%)')\n",
    "                plt.title('All Strategies Return Comparison by Ticker')\n",
    "                plt.xticks(x, comparison_df['Ticker'])\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Sharpe ratio comparison\n",
    "                plt.subplot(2, 1, 2)\n",
    "                \n",
    "                plt.bar(x - width, comparison_df['Weather_Sharpe'], width, label='Weather Strategy')\n",
    "                plt.bar(x, comparison_df['Basic_Sharpe'], width, label='Basic Strategy')\n",
    "                plt.bar(x + width, comparison_df['SMA_Sharpe'], width, label='SMA Strategy')\n",
    "                \n",
    "                plt.xlabel('Ticker')\n",
    "                plt.ylabel('Sharpe Ratio')\n",
    "                plt.title('Sharpe Ratio Comparison by Ticker')\n",
    "                plt.xticks(x, comparison_df['Ticker'])\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(weather_data_dir, 'all_strategies_comparison.png'))\n",
    "                plt.close()\n",
    "                \n",
    "                # Create a summary table for the impact report\n",
    "                strategy_table = pd.DataFrame({\n",
    "                    'Strategy': ['Weather-Sensitive', 'Basic (No Weather)', 'SMA', 'Buy and Hold'],\n",
    "                    'Avg Return (%)': [\n",
    "                        f\"{comparison_df['Weather_Return'].mean() * 100:.2f}%\",\n",
    "                        f\"{comparison_df['Basic_Return'].mean() * 100:.2f}%\",\n",
    "                        f\"{comparison_df['SMA_Return'].mean() * 100:.2f}%\",\n",
    "                        f\"{comparison_df['BuyHold_Return'].mean() * 100:.2f}%\"\n",
    "                    ],\n",
    "                    'Avg Sharpe': [\n",
    "                        f\"{comparison_df['Weather_Sharpe'].mean():.2f}\",\n",
    "                        f\"{comparison_df['Basic_Sharpe'].mean():.2f}\",\n",
    "                        f\"{comparison_df['SMA_Sharpe'].mean():.2f}\",\n",
    "                        \"N/A\"\n",
    "                    ]\n",
    "                })\n",
    "                \n",
    "                # Add strategy comparison to the impact report\n",
    "                with open(os.path.join(weather_data_dir, 'weather_impact_report.md'), 'a') as f:\n",
    "                    f.write(\"\\n\\n## Strategy Comparison\\n\\n\")\n",
    "                    f.write(\"We compared our weather-sensitive trading strategy against several baselines:\\n\\n\")\n",
    "                    f.write(\"1. **Basic Model**: Uses the same prediction model but without weather features\\n\")\n",
    "                    f.write(\"2. **Simple Moving Average (SMA)**: A technical analysis strategy using short and long-term moving averages\\n\")\n",
    "                    f.write(\"3. **Buy and Hold**: Simple strategy of buying at the beginning of the period and holding until the end\\n\\n\")\n",
    "                    f.write(\"### Performance Summary\\n\\n\")\n",
    "                    f.write(strategy_table.to_markdown(index=False))\n",
    "                    f.write(\"\\n\\n\")\n",
    "                    \n",
    "                    # Add interpretation based on results\n",
    "                    weather_return = comparison_df['Weather_Return'].mean() * 100\n",
    "                    basic_return = comparison_df['Basic_Return'].mean() * 100\n",
    "                    sma_return = comparison_df['SMA_Return'].mean() * 100\n",
    "                    buyhold_return = comparison_df['BuyHold_Return'].mean() * 100\n",
    "                    \n",
    "                    f.write(\"### Interpretation\\n\\n\")\n",
    "                    \n",
    "                    if weather_return > max(basic_return, sma_return, buyhold_return):\n",
    "                        f.write(\"The weather-sensitive strategy outperformed all baseline strategies, demonstrating that incorporating weather data provides a significant advantage in stock trading. This confirms our hypothesis that weather conditions influence market behavior in ways that can be exploited for trading advantage.\\n\\n\")\n",
    "                    elif weather_return > basic_return:\n",
    "                        f.write(\"The weather-sensitive strategy outperformed the basic model but not all baseline strategies. This suggests that weather data does provide some valuable signal, but may need to be combined with other technical indicators for optimal performance.\\n\\n\")\n",
    "                    else:\n",
    "                        f.write(\"The weather-sensitive strategy did not outperform the baseline strategies in our test period. This suggests that either the relationship between weather and stock performance is weaker than hypothesized, or our current implementation does not optimally capture this relationship.\\n\\n\")\n",
    "                    \n",
    "                    f.write(\"These results suggest that \" + (\n",
    "                        \"weather data should be considered a valuable feature in trading systems.\" if weather_return > basic_return else \n",
    "                        \"further refinement is needed to effectively leverage weather data in trading systems.\"\n",
    "                    ))\n",
    "                \n",
    "                print(\"Strategy comparison completed and added to impact report.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating comparison visualization: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing strategies: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4218b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Fixed Weather-Sensitive Trading Strategy ---\n",
      "Weather sensitive stocks selected: ['AOS', 'AES', 'ANET', 'ALL', 'APH']\n",
      "Using key weather features: ['wind_speed_10m_max', 'wind_speed_10m_max_lag2', 'wind_speed_10m_max_lag1']\n",
      "\n",
      "Running fixed strategy for AOS...\n",
      "\n",
      "=== Return Analysis ===\n",
      "Initial portfolio value: $10000.00\n",
      "Final portfolio value: $978349117.56\n",
      "Total return: 9783391.18%\n",
      "Number of suspicious daily returns (>50%): 0\n",
      "\n",
      "=== Biggest Value Jumps ===\n",
      "Date: 2023-01-31, Return: 13.44%, Value before: $353791695.63, Value after: $353791695.63\n",
      "Date: 2011-10-21, Return: 10.34%, Value before: $75585.19, Value after: $75585.19\n",
      "Date: 2021-10-28, Return: 9.80%, Value before: $82341794.60, Value after: $82341794.60\n",
      "Date: 2018-10-30, Return: 8.14%, Value before: $8464254.52, Value after: $8464254.52\n",
      "Date: 2020-05-18, Return: 7.65%, Value before: $26533142.04, Value after: $26533142.04\n",
      "Error in fixed weather strategy: 'Portfolio_Value'\n"
     ]
    }
   ],
   "source": [
    "# Debug function to identify return calculation issues\n",
    "def debug_returns(ticker_signals, initial_investment=10000):\n",
    "    \"\"\"Analyze portfolio value progression to identify unrealistic jumps\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Calculate daily returns and check for excessive values\n",
    "    ticker_signals = ticker_signals.sort_values('Date')\n",
    "    \n",
    "    # Initialize debugging columns\n",
    "    ticker_signals['Debug_Return'] = 0.0\n",
    "    ticker_signals['Debug_Value'] = initial_investment\n",
    "    ticker_signals['Is_Suspicious'] = False\n",
    "    \n",
    "    for i in range(1, len(ticker_signals)):\n",
    "        prev_value = ticker_signals['Debug_Value'].iloc[i-1]\n",
    "        curr_value = ticker_signals['Portfolio_Value'].iloc[i]\n",
    "        \n",
    "        # Calculate daily return\n",
    "        daily_return = (curr_value / prev_value) - 1\n",
    "        \n",
    "        # Flag suspicious returns (e.g., >50% daily gain)\n",
    "        is_suspicious = abs(daily_return) > 0.5\n",
    "        \n",
    "        # Store debug values\n",
    "        ticker_signals.loc[ticker_signals.index[i], 'Debug_Return'] = daily_return\n",
    "        ticker_signals.loc[ticker_signals.index[i], 'Debug_Value'] = curr_value\n",
    "        ticker_signals.loc[ticker_signals.index[i], 'Is_Suspicious'] = is_suspicious\n",
    "    \n",
    "    # Find the biggest jumps\n",
    "    biggest_jumps = ticker_signals.sort_values('Debug_Return', ascending=False).head(5)\n",
    "    \n",
    "    print(\"\\n=== Return Analysis ===\")\n",
    "    print(f\"Initial portfolio value: ${initial_investment:.2f}\")\n",
    "    print(f\"Final portfolio value: ${ticker_signals['Portfolio_Value'].iloc[-1]:.2f}\")\n",
    "    print(f\"Total return: {(ticker_signals['Portfolio_Value'].iloc[-1] / initial_investment - 1) * 100:.2f}%\")\n",
    "    print(f\"Number of suspicious daily returns (>50%): {ticker_signals['Is_Suspicious'].sum()}\")\n",
    "    \n",
    "    print(\"\\n=== Biggest Value Jumps ===\")\n",
    "    for _, row in biggest_jumps.iterrows():\n",
    "        print(f\"Date: {row['Date'].strftime('%Y-%m-%d')}, \"\n",
    "              f\"Return: {row['Debug_Return']*100:.2f}%, \"\n",
    "              f\"Value before: ${row['Debug_Value']:.2f}, \" \n",
    "              f\"Value after: ${row['Portfolio_Value']:.2f}\")\n",
    "    \n",
    "    return ticker_signals\n",
    "\n",
    "# Fixed trading strategy with improved error handling for realistic returns\n",
    "def fixed_weather_strategy(ticker_data, base_model, all_model, base_features, all_features, \n",
    "                          key_weather_features, initial_investment=10000):\n",
    "    \"\"\"\n",
    "    Fixed version of the weather-sensitive trading strategy with better return calculations\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    print(f\"\\nRunning fixed strategy for {ticker_data['Ticker'].iloc[0]}...\")\n",
    "    \n",
    "    # Prepare features for base model\n",
    "    X_base = ticker_data[base_features]\n",
    "    scaler_base = StandardScaler()\n",
    "    X_base_scaled = scaler_base.fit_transform(X_base)\n",
    "    \n",
    "    # Get base predictions\n",
    "    base_pred = base_model.predict(X_base_scaled)\n",
    "    base_prob = base_model.predict_proba(X_base_scaled)[:, 1]\n",
    "    \n",
    "    # Prepare features for weather model\n",
    "    X_all = ticker_data[all_features]\n",
    "    scaler_all = StandardScaler()\n",
    "    X_all_scaled = scaler_all.fit_transform(X_all)\n",
    "    \n",
    "    # Get weather model predictions\n",
    "    all_pred = all_model.predict(X_all_scaled)\n",
    "    all_prob = all_model.predict_proba(X_all_scaled)[:, 1]\n",
    "    \n",
    "    # Create signals dataframe\n",
    "    ticker_signals = pd.DataFrame({\n",
    "        'Date': ticker_data['Date'],\n",
    "        'Ticker': ticker_data['Ticker'],\n",
    "        'Close': ticker_data['Close'],\n",
    "        'Base_Signal': base_pred,\n",
    "        'Base_Confidence': base_prob,\n",
    "        'Weather_Signal': all_pred,\n",
    "        'Weather_Confidence': all_prob\n",
    "    })\n",
    "    \n",
    "    # Add key weather indicators\n",
    "    for feature in key_weather_features:\n",
    "        if feature in ticker_data.columns:\n",
    "            ticker_signals[feature] = ticker_data[feature]\n",
    "            \n",
    "            # Identify extreme values (top and bottom 10%)\n",
    "            feature_q90 = ticker_data[feature].quantile(0.90)\n",
    "            feature_q10 = ticker_data[feature].quantile(0.10)\n",
    "            \n",
    "            ticker_signals[f'{feature}_extreme_high'] = (ticker_data[feature] > feature_q90).astype(int)\n",
    "            ticker_signals[f'{feature}_extreme_low'] = (ticker_data[feature] < feature_q10).astype(int)\n",
    "    \n",
    "    # Create a weather extremity score\n",
    "    extreme_cols = [col for col in ticker_signals.columns if 'extreme_high' in col or 'extreme_low' in col]\n",
    "    if extreme_cols:\n",
    "        ticker_signals['weather_extremity'] = ticker_signals[extreme_cols].sum(axis=1)\n",
    "    else:\n",
    "        ticker_signals['weather_extremity'] = 0\n",
    "    \n",
    "    # Add season information if available\n",
    "    if 'season' in ticker_data.columns:\n",
    "        ticker_signals['season'] = ticker_data['season']\n",
    "    \n",
    "    # Sort by date for chronological simulation\n",
    "    ticker_signals = ticker_signals.sort_values('Date')\n",
    "    \n",
    "    # Create strategy signals\n",
    "    ticker_signals['Strategy_Signal'] = 'Hold'\n",
    "    \n",
    "    # Both models predict buy\n",
    "    buy_mask = (ticker_signals['Base_Signal'] == 1) & (ticker_signals['Weather_Signal'] == 1)\n",
    "    ticker_signals.loc[buy_mask, 'Strategy_Signal'] = 'Buy'\n",
    "    \n",
    "    # Both models predict sell\n",
    "    sell_mask = (ticker_signals['Base_Signal'] == 0) & (ticker_signals['Weather_Signal'] == 0)\n",
    "    ticker_signals.loc[sell_mask, 'Strategy_Signal'] = 'Sell'\n",
    "    \n",
    "    # Models disagree but extreme weather\n",
    "    extreme_mask = ticker_signals['weather_extremity'] >= 1\n",
    "    \n",
    "    # Weather says buy, base says sell, extreme weather\n",
    "    weather_buy_mask = (ticker_signals['Weather_Signal'] == 1) & (ticker_signals['Base_Signal'] == 0) & extreme_mask\n",
    "    ticker_signals.loc[weather_buy_mask, 'Strategy_Signal'] = 'Buy_Weather'\n",
    "    \n",
    "    # Weather says sell, base says buy, extreme weather\n",
    "    weather_sell_mask = (ticker_signals['Weather_Signal'] == 0) & (ticker_signals['Base_Signal'] == 1) & extreme_mask\n",
    "    ticker_signals.loc[weather_sell_mask, 'Strategy_Signal'] = 'Sell_Weather'\n",
    "    \n",
    "    # Initialize portfolio tracking - WEATHER STRATEGY\n",
    "    ticker_signals['Position'] = 0  # 0 = no position, 1 = long position\n",
    "    ticker_signals['Position_Size'] = 0.0  # Percentage of portfolio\n",
    "    ticker_signals['Portfolio_Value'] = initial_investment  # Initialize all rows\n",
    "    ticker_signals['Cash'] = initial_investment  # Initialize all rows\n",
    "    ticker_signals['Shares'] = 0  # Initialize all rows\n",
    "    ticker_signals['Trade'] = 'None'\n",
    "    ticker_signals['Trade_Price'] = np.nan\n",
    "    ticker_signals['Return'] = 0.0\n",
    "    \n",
    "    # Initialize portfolio tracking - BASIC STRATEGY  \n",
    "    ticker_signals['Basic_Position'] = 0\n",
    "    ticker_signals['Basic_Portfolio'] = initial_investment  # Initialize all rows\n",
    "    ticker_signals['Basic_Cash'] = initial_investment  # Initialize all rows\n",
    "    ticker_signals['Basic_Shares'] = 0  # Initialize all rows\n",
    "    ticker_signals['Basic_Trade'] = 'None'\n",
    "    ticker_signals['Basic_Return'] = 0.0\n",
    "    \n",
    "    # Trading parameters\n",
    "    transaction_cost_pct = 0.001  # 0.1% per trade\n",
    "    slippage_pct = 0.001  # 0.1% slippage\n",
    "    \n",
    "    # WEATHER STRATEGY SIMULATION\n",
    "    for i in range(1, len(ticker_signals)):\n",
    "        prev_idx = ticker_signals.index[i-1]\n",
    "        curr_idx = ticker_signals.index[i]\n",
    "        \n",
    "        # Get previous and current state\n",
    "        prev_row = ticker_signals.loc[prev_idx]\n",
    "        curr_row = ticker_signals.loc[curr_idx]\n",
    "        \n",
    "        # Default: carry forward previous position and values\n",
    "        ticker_signals.loc[curr_idx, 'Position'] = prev_row['Position']\n",
    "        ticker_signals.loc[curr_idx, 'Cash'] = prev_row['Cash']\n",
    "        ticker_signals.loc[curr_idx, 'Shares'] = prev_row['Shares']\n",
    "        ticker_signals.loc[curr_idx, 'Position_Size'] = prev_row['Position_Size']\n",
    "        \n",
    "        # Calculate current value before any trades (mark-to-market)\n",
    "        if prev_row['Position'] == 1:\n",
    "            # Value existing position at current price\n",
    "            shares_value = prev_row['Shares'] * curr_row['Close']\n",
    "            curr_portfolio_value = shares_value + prev_row['Cash']\n",
    "        else:\n",
    "            # Just cash\n",
    "            curr_portfolio_value = prev_row['Cash']\n",
    "        \n",
    "        # Execute trades based on signals\n",
    "        if prev_row['Strategy_Signal'] in ['Buy', 'Buy_Weather'] and prev_row['Position'] == 0:\n",
    "            # Determine position size\n",
    "            position_size = 1.0 if prev_row['Strategy_Signal'] == 'Buy' else 0.75\n",
    "            \n",
    "            # Buy with slippage\n",
    "            buy_price = prev_row['Close'] * (1 + slippage_pct)\n",
    "            cash_to_invest = prev_row['Cash'] * position_size\n",
    "            transaction_cost = cash_to_invest * transaction_cost_pct\n",
    "            available_cash = cash_to_invest - transaction_cost\n",
    "            \n",
    "            # Calculate shares and remaining cash\n",
    "            shares_to_buy = available_cash / buy_price if buy_price > 0 else 0\n",
    "            cash_remaining = prev_row['Cash'] - cash_to_invest\n",
    "            \n",
    "            # Update position\n",
    "            ticker_signals.loc[curr_idx, 'Position'] = 1\n",
    "            ticker_signals.loc[curr_idx, 'Position_Size'] = position_size\n",
    "            ticker_signals.loc[curr_idx, 'Cash'] = cash_remaining\n",
    "            ticker_signals.loc[curr_idx, 'Shares'] = shares_to_buy\n",
    "            ticker_signals.loc[curr_idx, 'Trade'] = 'Buy'\n",
    "            ticker_signals.loc[curr_idx, 'Trade_Price'] = buy_price\n",
    "            \n",
    "            # Calculate new portfolio value after trade\n",
    "            new_shares_value = shares_to_buy * curr_row['Close']\n",
    "            ticker_signals.loc[curr_idx, 'Portfolio_Value'] = new_shares_value + cash_remaining\n",
    "            \n",
    "        elif prev_row['Strategy_Signal'] in ['Sell', 'Sell_Weather'] and prev_row['Position'] == 1:\n",
    "            # Sell with slippage\n",
    "            sell_price = prev_row['Close'] * (1 - slippage_pct)\n",
    "            shares_value = prev_row['Shares'] * sell_price\n",
    "            transaction_cost = shares_value * transaction_cost_pct\n",
    "            cash_after_sale = shares_value - transaction_cost + prev_row['Cash']\n",
    "            \n",
    "            # Update position\n",
    "            ticker_signals.loc[curr_idx, 'Position'] = 0\n",
    "            ticker_signals.loc[curr_idx, 'Position_Size'] = 0.0\n",
    "            ticker_signals.loc[curr_idx, 'Cash'] = cash_after_sale\n",
    "            ticker_signals.loc[curr_idx, 'Shares'] = 0\n",
    "            ticker_signals.loc[curr_idx, 'Trade'] = 'Sell'\n",
    "            ticker_signals.loc[curr_idx, 'Trade_Price'] = sell_price\n",
    "            \n",
    "            # Portfolio value after selling is just cash\n",
    "            ticker_signals.loc[curr_idx, 'Portfolio_Value'] = cash_after_sale\n",
    "        else:\n",
    "            # No trade, just update portfolio value\n",
    "            ticker_signals.loc[curr_idx, 'Portfolio_Value'] = curr_portfolio_value\n",
    "        \n",
    "        # Calculate daily return - prevent division by zero\n",
    "        if prev_row['Portfolio_Value'] > 0:\n",
    "            ticker_signals.loc[curr_idx, 'Return'] = (\n",
    "                ticker_signals.loc[curr_idx, 'Portfolio_Value'] / \n",
    "                prev_row['Portfolio_Value'] - 1\n",
    "            )\n",
    "        else:\n",
    "            ticker_signals.loc[curr_idx, 'Return'] = 0\n",
    "    \n",
    "    # BASIC STRATEGY SIMULATION\n",
    "    for i in range(1, len(ticker_signals)):\n",
    "        prev_idx = ticker_signals.index[i-1]\n",
    "        curr_idx = ticker_signals.index[i]\n",
    "        \n",
    "        # Get previous and current state\n",
    "        prev_row = ticker_signals.loc[prev_idx]\n",
    "        curr_row = ticker_signals.loc[curr_idx]\n",
    "        \n",
    "        # Default: carry forward\n",
    "        ticker_signals.loc[curr_idx, 'Basic_Position'] = prev_row['Basic_Position']\n",
    "        ticker_signals.loc[curr_idx, 'Basic_Cash'] = prev_row['Basic_Cash']\n",
    "        ticker_signals.loc[curr_idx, 'Basic_Shares'] = prev_row['Basic_Shares']\n",
    "        \n",
    "        # Calculate current value before any trades\n",
    "        if prev_row['Basic_Position'] == 1:\n",
    "            # Value existing position at current price\n",
    "            shares_value = prev_row['Basic_Shares'] * curr_row['Close']\n",
    "            curr_portfolio_value = shares_value + prev_row['Basic_Cash']\n",
    "        else:\n",
    "            # Just cash\n",
    "            curr_portfolio_value = prev_row['Basic_Cash']\n",
    "        \n",
    "        # Execute trades based on base model signals\n",
    "        basic_signal = 'Buy' if prev_row['Base_Signal'] == 1 else 'Sell'\n",
    "        \n",
    "        if basic_signal == 'Buy' and prev_row['Basic_Position'] == 0:\n",
    "            # Buy with costs\n",
    "            buy_price = prev_row['Close'] * (1 + slippage_pct)\n",
    "            transaction_cost = prev_row['Basic_Cash'] * transaction_cost_pct\n",
    "            available_cash = prev_row['Basic_Cash'] - transaction_cost\n",
    "            \n",
    "            # Calculate shares\n",
    "            shares_to_buy = available_cash / buy_price if buy_price > 0 else 0\n",
    "            \n",
    "            # Update position\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Position'] = 1\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Cash'] = 0\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Shares'] = shares_to_buy\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Trade'] = 'Buy'\n",
    "            \n",
    "            # Portfolio value after buying\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Portfolio'] = shares_to_buy * curr_row['Close']\n",
    "            \n",
    "        elif basic_signal == 'Sell' and prev_row['Basic_Position'] == 1:\n",
    "            # Sell with costs\n",
    "            sell_price = prev_row['Close'] * (1 - slippage_pct)\n",
    "            shares_value = prev_row['Basic_Shares'] * sell_price\n",
    "            transaction_cost = shares_value * transaction_cost_pct\n",
    "            cash_after_sale = shares_value - transaction_cost\n",
    "            \n",
    "            # Update position\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Position'] = 0\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Cash'] = cash_after_sale\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Shares'] = 0\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Trade'] = 'Sell'\n",
    "            \n",
    "            # Portfolio value after selling is just cash\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Portfolio'] = cash_after_sale\n",
    "        else:\n",
    "            # No trade, just update portfolio value\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Portfolio'] = curr_portfolio_value\n",
    "        \n",
    "        # Calculate daily return - prevent division by zero\n",
    "        if prev_row['Basic_Portfolio'] > 0:\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Return'] = (\n",
    "                ticker_signals.loc[curr_idx, 'Basic_Portfolio'] / \n",
    "                prev_row['Basic_Portfolio'] - 1\n",
    "            )\n",
    "        else:\n",
    "            ticker_signals.loc[curr_idx, 'Basic_Return'] = a0\n",
    "    \n",
    "    # Calculate cumulative returns\n",
    "    ticker_signals['Cum_Return'] = (1 + ticker_signals['Return']).cumprod()\n",
    "    ticker_signals['Basic_Cum_Return'] = (1 + ticker_signals['Basic_Return']).cumprod()\n",
    "    \n",
    "    # Add buy-and-hold benchmark\n",
    "    ticker_signals['BuyHold_Return'] = ticker_signals['Close'] / ticker_signals['Close'].iloc[0]\n",
    "    \n",
    "    # Run debug analysis\n",
    "    debug_weather = debug_returns(ticker_signals[['Date', 'Portfolio_Value']], initial_investment)\n",
    "    debug_basic = debug_returns(ticker_signals[['Date', 'Basic_Portfolio']], initial_investment)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    final_weather_return = ticker_signals['Portfolio_Value'].iloc[-1] / initial_investment - 1\n",
    "    final_basic_return = ticker_signals['Basic_Portfolio'].iloc[-1] / initial_investment - 1\n",
    "    final_buy_hold = ticker_signals['BuyHold_Return'].iloc[-1] - 1\n",
    "    \n",
    "    print(f\"\\n{ticker_signals['Ticker'].iloc[0]} Performance Summary:\")\n",
    "    print(f\"Weather-Sensitive Strategy Return: {final_weather_return:.4f} ({final_weather_return * 100:.2f}%)\")\n",
    "    print(f\"Basic Strategy Return: {final_basic_return:.4f} ({final_basic_return * 100:.2f}%)\")\n",
    "    print(f\"Buy and Hold Return: {final_buy_hold:.4f} ({final_buy_hold * 100:.2f}%)\")\n",
    "    print(f\"Outperformance vs Basic: {(final_weather_return - final_basic_return) * 100:.2f}%\")\n",
    "    \n",
    "    # Create visualization\n",
    "    try:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Portfolio value chart\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.plot(ticker_signals['Date'], ticker_signals['Portfolio_Value'], label='Weather Strategy')\n",
    "        plt.plot(ticker_signals['Date'], ticker_signals['Basic_Portfolio'], label='Basic Strategy')\n",
    "        plt.axhline(y=initial_investment, color='k', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        # Mark weather strategy trades\n",
    "        buys = ticker_signals[ticker_signals['Trade'] == 'Buy']\n",
    "        sells = ticker_signals[ticker_signals['Trade'] == 'Sell']\n",
    "        \n",
    "        if len(buys) > 0:\n",
    "            plt.scatter(buys['Date'], buys['Portfolio_Value'], \n",
    "                        marker='^', color='green', s=100, label='Buy')\n",
    "        if len(sells) > 0:\n",
    "            plt.scatter(sells['Date'], sells['Portfolio_Value'], \n",
    "                        marker='v', color='red', s=100, label='Sell')\n",
    "        \n",
    "        plt.title(f'{ticker_signals[\"Ticker\"].iloc[0]} Portfolio Performance')\n",
    "        plt.ylabel('Portfolio Value ($)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Weather extremity and trades\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.bar(ticker_signals['Date'], ticker_signals['weather_extremity'], \n",
    "                color='skyblue', alpha=0.6, label='Weather Extremity')\n",
    "        \n",
    "        # Mark weather-based trades\n",
    "        weather_buys = ticker_signals[ticker_signals['Strategy_Signal'] == 'Buy_Weather']\n",
    "        weather_sells = ticker_signals[ticker_signals['Strategy_Signal'] == 'Sell_Weather']\n",
    "        \n",
    "        if len(weather_buys) > 0:\n",
    "            plt.scatter(weather_buys['Date'], weather_buys['weather_extremity'] + 0.2, \n",
    "                       marker='^', color='green', s=80, label='Weather Buy Signal')\n",
    "        \n",
    "        if len(weather_sells) > 0:\n",
    "            plt.scatter(weather_sells['Date'], weather_sells['weather_extremity'] + 0.2, \n",
    "                       marker='v', color='red', s=80, label='Weather Sell Signal')\n",
    "        \n",
    "        plt.title(f'{ticker_signals[\"Ticker\"].iloc[0]} Weather Extremity and Weather-Based Trades')\n",
    "        plt.ylabel('Weather Extremity Score')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Cumulative returns comparison\n",
    "        plt.subplot(3, 1, 3)\n",
    "        \n",
    "        plt.plot(ticker_signals['Date'], ticker_signals['Cum_Return'], \n",
    "                label='Weather-Sensitive Strategy', color='blue')\n",
    "        plt.plot(ticker_signals['Date'], ticker_signals['Basic_Cum_Return'], \n",
    "                label='Basic Strategy', color='orange', linestyle='--')\n",
    "        plt.plot(ticker_signals['Date'], ticker_signals['BuyHold_Return'], \n",
    "                label='Buy and Hold', color='green', linestyle=':')\n",
    "        \n",
    "        plt.title(f'{ticker_signals[\"Ticker\"].iloc[0]} Cumulative Returns Comparison')\n",
    "        plt.ylabel('Cumulative Return (Starting = 1)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(weather_data_dir, f'{ticker_signals[\"Ticker\"].iloc[0]}_fixed_strategy.png'))\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating visualization: {e}\")\n",
    "    \n",
    "    return ticker_signals\n",
    "\n",
    "# Main function to run fixed strategy with debugging\n",
    "def run_fixed_weather_strategy():\n",
    "    \"\"\"Run the fixed weather strategy with proper return calculations\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    \n",
    "    print(\"\\n--- Running Fixed Weather-Sensitive Trading Strategy ---\")\n",
    "    \n",
    "    try:\n",
    "        # Select tickers to analyze\n",
    "        if 'seasonal_impact_df' in globals() and len(seasonal_impact_df) > 0:\n",
    "            weather_sensitive_stocks = seasonal_impact_df.groupby('Ticker')['Weather_Impact'].mean()\n",
    "            weather_sensitive_stocks = weather_sensitive_stocks.sort_values(ascending=False).head(5).index.tolist()\n",
    "        else:\n",
    "            # Fallback: use top 5 stocks by data volume\n",
    "            weather_sensitive_stocks = combined_df['Ticker'].value_counts().head(5).index.tolist()\n",
    "        \n",
    "        print(f\"Weather sensitive stocks selected: {weather_sensitive_stocks}\")\n",
    "        \n",
    "        # Identify key weather features\n",
    "        key_weather_features = weather_in_top[:min(3, len(weather_in_top))]\n",
    "        print(f\"Using key weather features: {key_weather_features}\")\n",
    "        \n",
    "        # Run the fixed strategy for each ticker\n",
    "        strategy_results = []\n",
    "        performance_summary = []\n",
    "        \n",
    "        for ticker in weather_sensitive_stocks:\n",
    "            # Get ticker data\n",
    "            ticker_data = combined_df[combined_df['Ticker'] == ticker].copy()\n",
    "            \n",
    "            if len(ticker_data) < 50:\n",
    "                print(f\"Not enough data for {ticker}, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Run fixed strategy\n",
    "            ticker_results = fixed_weather_strategy(\n",
    "                ticker_data, base_model, all_model, \n",
    "                base_features, all_features, key_weather_features\n",
    "            )\n",
    "            \n",
    "            # Add to results\n",
    "            strategy_results.append(ticker_results)\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            final_weather_return = ticker_results['Portfolio_Value'].iloc[-1] / 10000 - 1\n",
    "            final_basic_return = ticker_results['Basic_Portfolio'].iloc[-1] / 10000 - 1\n",
    "            final_buy_hold = ticker_results['BuyHold_Return'].iloc[-1] - 1\n",
    "            \n",
    "            # Calculate risk metrics\n",
    "            weather_vol = ticker_results['Return'].std() * np.sqrt(252)  # Annualized\n",
    "            basic_vol = ticker_results['Basic_Return'].std() * np.sqrt(252)\n",
    "            \n",
    "            # Calculate Sharpe ratio (with error handling)\n",
    "            weather_sharpe = (final_weather_return / len(ticker_results) * 252) / max(weather_vol, 0.0001)\n",
    "            basic_sharpe = (final_basic_return / len(ticker_results) * 252) / max(basic_vol, 0.0001)\n",
    "            \n",
    "            # Count trades\n",
    "            weather_trades = len(ticker_results[ticker_results['Trade'] != 'None'])\n",
    "            basic_trades = len(ticker_results[ticker_results['Basic_Trade'] != 'None'])\n",
    "            \n",
    "            # Count profitable trades\n",
    "            profitable_weather = ticker_results[ticker_results['Trade'] == 'Sell']\n",
    "            profitable_weather = profitable_weather[profitable_weather['Return'] > 0]\n",
    "            weather_win_rate = len(profitable_weather) / max(1, len(ticker_results[ticker_results['Trade'] == 'Sell']))\n",
    "            \n",
    "            # Add to performance summary\n",
    "            performance_summary.append({\n",
    "                'Ticker': ticker,\n",
    "                'Weather_Return': final_weather_return,\n",
    "                'Basic_Return': final_basic_return,\n",
    "                'Buy_Hold_Return': final_buy_hold,\n",
    "                'Outperformance': final_weather_return - final_basic_return,\n",
    "                'Weather_Sharpe': weather_sharpe,\n",
    "                'Basic_Sharpe': basic_sharpe,\n",
    "                'Weather_Trades': weather_trades,\n",
    "                'Basic_Trades': basic_trades,\n",
    "                'Weather_Win_Rate': weather_win_rate\n",
    "            })\n",
    "        \n",
    "        # Create summary dataframe\n",
    "        if performance_summary:\n",
    "            summary_df = pd.DataFrame(performance_summary)\n",
    "            \n",
    "            # Print overall results\n",
    "            print(\"\\n=== Overall Fixed Weather-Sensitive Strategy Results ===\")\n",
    "            print(f\"Average Weather Strategy Return: {summary_df['Weather_Return'].mean():.4f} ({summary_df['Weather_Return'].mean() * 100:.2f}%)\")\n",
    "            print(f\"Average Basic Strategy Return: {summary_df['Basic_Return'].mean():.4f} ({summary_df['Basic_Return'].mean() * 100:.2f}%)\")\n",
    "            print(f\"Average Buy & Hold Return: {summary_df['Buy_Hold_Return'].mean():.4f} ({summary_df['Buy_Hold_Return'].mean() * 100:.2f}%)\")\n",
    "            print(f\"Average Outperformance: {summary_df['Outperformance'].mean():.4f} ({summary_df['Outperformance'].mean() * 100:.2f}%)\")\n",
    "            print(f\"Average Weather Sharpe: {summary_df['Weather_Sharpe'].mean():.4f}\")\n",
    "            print(f\"Average Basic Sharpe: {summary_df['Basic_Sharpe'].mean():.4f}\")\n",
    "            \n",
    "            # Create comparison plot\n",
    "            try:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                \n",
    "                x = np.arange(len(summary_df))\n",
    "                width = 0.25\n",
    "                \n",
    "                plt.bar(x - width, summary_df['Weather_Return'] * 100, width, label='Weather Strategy')\n",
    "                plt.bar(x, summary_df['Basic_Return'] * 100, width, label='Basic Strategy')\n",
    "                plt.bar(x + width, summary_df['Buy_Hold_Return'] * 100, width, label='Buy & Hold')\n",
    "                \n",
    "                plt.xlabel('Ticker')\n",
    "                plt.ylabel('Return (%)')\n",
    "                plt.title('Strategy Returns by Ticker')\n",
    "                plt.xticks(x, summary_df['Ticker'])\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(weather_data_dir, 'fixed_weather_strategy_comparison.png'))\n",
    "                plt.close()\n",
    "                \n",
    "                # Plot Sharpe ratio comparison\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                \n",
    "                plt.bar(x - width/2, summary_df['Weather_Sharpe'], width, label='Weather Strategy')\n",
    "                plt.bar(x + width/2, summary_df['Basic_Sharpe'], width, label='Basic Strategy')\n",
    "                \n",
    "                plt.xlabel('Ticker')\n",
    "                plt.ylabel('Sharpe Ratio')\n",
    "                plt.title('Strategy Sharpe Ratios by Ticker')\n",
    "                plt.xticks(x, summary_df['Ticker'])\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(weather_data_dir, 'fixed_weather_strategy_sharpe.png'))\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating summary plots: {e}\")\n",
    "            \n",
    "            return strategy_results, summary_df\n",
    "        else:\n",
    "            print(\"No performance summary data collected.\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error in fixed weather strategy: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Run the fixed strategy\n",
    "fixed_results, fixed_summary = run_fixed_weather_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfec57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
